#!/usr/bin/python3 -I

def check_perms():
    '''Because this program might be run as root, or with
    a random environment, check for some conditions that
    might cause security issues.
    '''
    import sys, os, stat
    user = os.getuid()
    if user == 1000: user = 501 # XXX Hack for VirtualBox under MacOS
    # First, clean up python search path by removing
    # dodgy entries.
    newp = []
    for x in sys.path:
        if x is '':
            continue
        try:
            sb = os.stat(x)
        except OSError:
            continue
        # Skip items not owned by root, unless
        # running as the owner of the item.
        if sb.st_uid != 0 and user != sb.st_uid:
            continue
        # Skip non-directories in path
        if not stat.S_ISDIR(sb.st_mode):
            continue
        # Skip things that others can modify
        mode = stat.S_IMODE(sb.st_mode)
        if (mode & (stat.S_IWGRP|stat.S_IWOTH)):
            continue
        if x not in newp:
            newp.append(x)
    # Update sys.path to what is left
    sys.path.clear()
    sys.path.extend(newp)

    # Now, check that we haven't already loaded
    # suspect items.
    for name, val in sys.modules.items():
        src = str(val)
        pcs = src.split()
        pathpart = pcs[-1]
        path = pathpart[1:-2]
        if path in ['built-in', 'frozen']:
            continue
        if name == '__main__':
            # For debugging, we might need to
            # add the directory where the script
            # resides back to sys.path, if
            # the -I flag removed it.
            t = os.path.dirname(path)
            t = os.path.abspath(t)
            if t not in sys.path:
                sys.path.insert(0, t)
            continue
        if "' from '" in src:
            sb = os.stat(path)
            if sb.st_uid != 0 and user != sb.st_uid:
                raise OSError("Unsafe PYTHONPATH with " + path)
check_perms()

import sys
import os
import argparse
import re
import subprocess
import signal
import socket
import time

import pbs_ifl as ifl
from nas_utils import BatchUtils
from nas_pbsutil import *
import nas_layout as layout
import nas_field_format
from nas_field_format import *

long_desc = '''Display information about jobs, queues, or servers

This command displays information about PBS jobs, queues, or servers,
writing the status to standard output. It is similar to OpenPBS's qstat, but
provides more options for selecting and formatting the output.
'''

args = None
gNAS = False
gNAS_job_data = {}
gNow = time.time()
gdebug = []
ghostname = ''
ghostnameshort = ''
gserver_info = dict()
gshare_data = dict()
gshare_entity_info = dict()
host_re = None
opts_W = list()
verbose = 0
version = "0.1.2"

conf.gNow = gNow
conf.pbs_conf = pbs_conf = ifl.cvar.pbs_conf

def main():
    global gNAS, verbose, args, opts_W, host_re, gdebug
    global ghostname, ghostnameshort
    # Don't catch any signals (so no ugly tracebacks on Ctrl-C).
    for i in range(1, signal.NSIG):
        try:
            signal.signal(i, signal.SIG_DFL)
        except:
            pass
    prog = sys.argv[0].split('/')[-1]
    parser = argparse.ArgumentParser(description=long_desc, prog=prog,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    thing_type = parser.add_mutually_exclusive_group()
    parser.add_argument('--version', action='version',
        version='%(prog)s ' + version)
    thing_type.add_argument('-B', default=False, action='store_true',
        help='Display information for servers')
    parser.add_argument('-G', default='b', action='store_const',
        dest='size_units', const='G',
        help='Display sizes in gigabytes')
    parser.add_argument('-H', default=False, action='store_true',
        help='Select only finished or moved jobs')
    parser.add_argument('-J', default=False, action='store_true',
        help='Display status information for job arrays')
    parser.add_argument('-M', default='b', action='store_const',
        dest='size_units', const='M',
        help='Display sizes in 8 byte megawords')
    thing_type.add_argument('-Q', default=False, action='store_true',
        help='Display information for queues')
    parser.add_argument('-W', action='append', metavar='display option',
        help='Options customizing field selection and display.')
    parser.add_argument('-a', default=False, action='store_true',
        help='Include information about server and compute resources')
    parser.add_argument('--debug', default=[], action='append',
        help='Debugging arguments (for developers)')
    parser.add_argument('-i', default=False, action='store_true',
        help='Select queued, held, or waiting jobs')
    parser.add_argument('-n', default=False, action='store_true',
        help='Include exec_host information')
    parser.add_argument('-r', default=False, action='store_true',
        help='Select running or suspended jobs')
    parser.add_argument('-s', default=False, action='store_true',
        help='Include job comment')
    parser.add_argument('-t', default=False, action='store_true',
        help='Display status information for jobs, job_arrays, and subjobs')
    parser.add_argument('-u',
        help='Display only jobs from this user')
    parser.add_argument('--verbose', '-v', default=0, action='count',
        help='Increase debugging verbosity')
    parser.add_argument('-x', default=False, action='store_true',
        help='Include finished and moved jobs')
    parser.add_argument('things', nargs='*',
        help='Jobs, queues, or servers to status')

    args = parser.parse_args()
    conf.verbose = verbose = args.verbose
    conf.gdebug = gdebug = ' '.join(args.debug)

    if (ifl.pbs_loadconf(0) == 0):
        print("Cannot get PBS configuration information", file=sys.stderr)
        return 1

    # Look at -B, -Q, and -a options to decide on default list of fields
    do_jobs = False
    if args.Q:
        default_fields = ['q_name', 'q_ncpus', 'q_ncpus_def', 'q_time', 'q_time_def', 'q_jm', 'state_count', 'q_pr', 'q_info']
        known_fields = gen_field_list_Q()
    elif args.B:
        default_fields = ['server_name', 'jm', 'state_count', 'default_queue', 'info']
        known_fields = gen_field_list_B()
    else:
        do_jobs = True
        default_fields = ['jobid', 'user', 'queue', 'jobname', 'cpus', 'nds',
            'reqdwallt', 's', 'elapwallt', 'eff']
        known_fields = gen_field_list()
        if verbose > 2:
            # Show titles of known fields
            l = []
            for x in known_fields:
                t = x['title']
                l.append(t if isinstance(t, str) else ' '.join(t))
            print('Known field titles', ', '.join(l))

    # Build list of known fields
    opts_W = args.W
    if opts_W is None:
        opts_W = list()
    conf.opts_W = opts_W
    # Make units for sizes available in opt_W
    opts_W.insert(0,args.size_units)
    # Get our hostname
    conf.ghostname = ghostname = socket.gethostname()
    conf.ghostnameshort = ghostnameshort = ghostname.split('.')[0]
    # Load possible user or system overrides
    more_code = load_userexits('qstat')
    if more_code:
        more_code = userexits_header + more_code
        if verbose > 2:
            print(more_code)
        prog = compile(more_code, 'userexit code', 'exec')
        exec(prog, globals(), locals())
    default_W = []
    userexit_post_opts(globals(), locals())
    opts_W[0:0] = default_W
    conf.gNAS = gNAS = check_W_bool('NAS')
    # Scan opts_W for on-the-fly field defs
    define_on_the_fly(known_fields, opts_W)
    # Set up formats
    fmtr = NAS_field_format(default_fields)
    fmtr.known_fields = known_fields
    userexit_add_fields(globals(), locals())
    # Handle -W formatting options
    # First, collect list of fields of interest and which PBS attributes
    # hold the values for those fields
    (field_list, attr_list, errs) = fmtr.collect_fields()
    if (errs):
        # Check if should just print list of fields
        if field_list == None:
            print('\n'.join(errs))
            return 0
        print(errs, file = sys.stderr)
    # Adjust formatting of selected fields, per -W fmt_xxx values
    fmtr.field_list = field_list
    rc = fmtr.adjust_formats(field_list)
    if rc != True:
        print(rc, file=sys.stderr)
        return 1
    # Set formatting globals from cmd line args
    nas_field_format.set_field_vars(opts_W)
    # Decide if will be filtering based on execution host
    host_patt = check_W_str('host')
    if host_patt == None:
        host_patt = check_W_str('hosts')
    # Convert host list in form aaa,bbb,ccc to pattern alternative aaa|bbb|ccc
    # and compile it.
    if host_patt:
        host_re = re.compile(r'\b('+host_patt.replace(',','|')+r')\b', re.I)
    else:
        host_re = None
    if do_jobs and host_re:
        # If we are filtering by host, make sure we ask for exec_host
        attr_list.add('exec_host')
    # Similarly, -n requires exec_host and -s requires comment
    if do_jobs and args.n:
        attr_list.add('exec_host')
    if do_jobs and args.s:
        attr_list.add('comment')
    # If filtering by user/job, make sure we have those
    if check_W_str('u'):
        attr_list.add('Job_Owner')
        attr_list.add('Job_Name')
    # Build list of attributes we need to ask for.
    bu = BatchUtils()
    attr_list = (','.join(attr_list)).split(',')
    while '' in attr_list:
        attr_list.remove('')
    if verbose > 2:
        print('Requested attribute list:', ', '.join(attr_list))
    # An empty attribute list is rejected. For servers and queues, just
    # ask for everything. For jobs, ask for something easy.
    if len(attr_list) > 0:
        atl = bu.list_to_attrl(attr_list)
    else:
        if do_jobs:
            t = ['job_state']
            atl = bu.list_to_attrl(t)
        else:
            atl = None
    fmtr.atl = atl

    # Last, get and display requested information
    if args.Q:
        rc = display_queues(args, fmtr)
    elif args.B:
        rc = display_servers(args, fmtr)
    else:
        rc = display_jobs(args, fmtr)
    return rc

def display_jobs(args, fmtr):
    '''Output job info

    For each job, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W, host_re, gdebug

    # Examine options to set selection and extend attributes
    selects = dict()
    extend = set()
    if args.i:
        selects['job_state'] = 'HQTW'
    if args.r or host_re:
        selects['job_state'] = 'BERSU'
    if args.H:
        selects['job_state'] = 'FMX'
        extend.add('x')
    if args.t:
        extend.add('t')
    if args.x:
        extend.add('x')
    if args.u:
        selects['euser'] = args.u
    if args.J:
        selects['array'] = 'True'
    extend = ''.join(extend)

    alt_disp = True if args.a else False

    # Build base layout
    cfg = layout.Config()
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, ident=fld['name'], **fld['format'])
    # Gather data from server
    server_conn = {'': None, None: None}
    bu = BatchUtils()
    sel_attr = bu.dict_to_attropl(selects, ifl.EQ)
    things = args.things
    errcnt = 0
    if len(things) == 0:
        # No destinations, ask for jobs at default server
        things.append('@' + pbs_conf.pbs_server_name)
    # There can be three types of objects to get job info for:
    # individual jobs, queues, and servers. Distinguish them
    info = []
    idx = 0
    while idx < len(things):
        thing = things[idx].strip()
        idx += 1
        seq_num = None
        is_jobs = False
        if thing[0] not in '123456789':
            # Server or queue
            if thing[0] is '@':
                queue = None
                names = [thing]
                current_server = thing[1:]
            else:
                t = thing.split('@')
                queue = t[0]
                names = [queue]
                current_server = t[1] if len(t) > 1 else None
        else:
            is_jobs = True
            # Job id
            try:
                (seq_num, parent_server, current_server, array_idx, _) = \
                    parse_jobid(thing)
            except:
                print("Unrecognized destination: %s" % thing,
                    file = sys.stderr)
                errcnt += 1
                continue
            # Collect sequence of jobids at same server into one list.
            names = []
            jobid = seq_num
            if not parent_server:
                if current_server:
                    parent_server = current_server
                else:
                    parent_server = pbs_conf.pbs_server_name
            if array_idx:
                jobid += array_idx
            jobid += '.' + parent_server
            add_server_conn(server_conn, parent_server, None)
            if current_server and current_server not in server_conn:
                conn = ifl.pbs_connect(current_server)
                add_server_conn(server_conn, current_server, conn)
            names.append(jobid)
            prev_conn = server_conn[current_server]
            # Examine next entry to see if more jobids
            while idx < len(things):
                peek = things[idx]
                if peek[0] not in '123456789':
                    break
                try:
                    (s, p, c, a, _) = parse_jobid(peek)
                except:
                    c = None
                # Detect change of server
                if server_conn.get(c, -2) != prev_conn:
                    break
                jobid = s
                if a:
                    jobid += a
                if not p:
                    if c:
                        p = current_server
                    else:
                        p = pbs_conf.pbs_server_name
                jobid += '.' + p
                names.append(jobid)
                idx += 1
        # Now, issue query to current_server
        if current_server == None:
            current_server = pbs_conf.pbs_server_name
        conn = server_conn.get(current_server, None)
        if conn == None:
            conn = ifl.pbs_connect(current_server)
            add_server_conn(server_conn, current_server, conn)
            if conn < 0:
                print("Cannot connect to PBS server %s: %s" % \
                    (current_server, os.strerror(ifl.get_pbs_errno())),
                    file = sys.stderr)
                errcnt += 1
                continue
        if conn == -1:
            # Known bad server name, skip
            continue
        # If running at NAS, cache share & priority info
        if gNAS:
            cache_shares(current_server)
            extract_share_info(current_server)
            extract_job_info(current_server)
        set_entity_map(gshare_entity_info)
        # Give userexits a chance to adjust things based on server
        userexit_set_server(globals(), locals())
        # Display server header, if requested
        if alt_disp:
            cache_server(current_server, conn)
            display_server_hdr(current_server, conn, args, opts_W)
        if gNAS and check_W_int('shares', 0):
            display_shares(gshare_entity_info)
        # Get info for selected jobs
        sname = current_server.split('.')[0]
        bs = file_to_stat(sname, 'jobs', fmtr.atl)
        if bs is None:
            if sel_attr:
                bs = ifl.pbs_selstat(conn, sel_attr, fmtr.atl, extend)
            else:
                namelist = ','.join(names)
                bs = ifl.pbs_statjob(conn, namelist, fmtr.atl, extend)
            err = ifl.get_pbs_errno()
            if err:
                errcnt += 1
                errmsg = ifl.pbs_geterrmsg(conn)
                if errmsg == None or errmsg == '':
                    errmsg = "error %d" % err
                errmsg += ': ' + namelist
                print(errmsg,
                    file = sys.stderr)
                continue
        if gNAS:
            plug_job_info(bs)
        # If interested only in jobs on given host, filter the list
        if host_re:
            newbs = []
            for job in bs:
                hosts = job.get('exec_host')
                if not hosts:
                    continue
                if not host_re.search(hosts):
                    continue
                newbs.append(job)
            bs = newbs
        # If interested only in specific user jobs, filter the list
        ulist = check_W_str('u')
        if ulist:
            patts = ulist.split(',')
            patt_re = []
            for t in patts:
                if not '#' in t:
                    t = t + '#.*'
                # Convert negated patterns to negative look-ahead
                if t.startswith('!'):
                    t = '(?!' + t[1:] + ').*'
                try:
                    r = re.compile(t + '$')
                except:
                    continue
                patt_re.append(r)
            newbs = []
            for job in bs:
                owner = job.get('Job_Owner','').split('@')[0]
                jobname = job.get('Job_Name','')
                for r in patt_re:
                    if r.match(owner + '#' + jobname):
                        newbs.append(job)
                        break
            bs = newbs
        if sel_attr and names and is_jobs:
            # You cannot specify a list of names to the pbs_selstat()
            # call, so we have to filter the results ourselves when
            # explicit request IDs were given.
            newbs = []
            name_set = set(names)
            found = set()
            for job in bs:
                jobid = job['id']
                if jobid in name_set:
                    found.add(jobid)
                    newbs.append(job)
            bs = newbs
            missing = name_set.difference(found)
            if missing:
                print("Excluded Job Id%s:" % ('' if len(missing) == 1 else 's'),\
                    ' '.join(missing), \
                    file = sys.stderr)
        if bs:
            info.extend(bs)
        names = []
    # End of idx loop
    # Close server connections
    for conn in set(server_conn.values()):
        if conn != None and conn != -1:
            ifl.pbs_disconnect(conn)
    # Tag sort job list
    def cmpf(i):
        def safeint(x):
            try:
                t = int(x)
            except:
                t = 0
            return t
        job = info[i]
        st = job.get('job_state','?')
        k1 = 'BRQHWTEX'.find(st)
        if st in 'BR':
            k2 = safeint(job.get('Priority','0'))
            k3 = job.get('queue','')
            k4 = safeint(job.get('Resource_List.nodect','0'))
            k4 = safeint(job.get('Resource_List.ncpus','0'))
            k5 = clocktosecs(job.get('Resource_List.walltime',''))
            if not isinstance(k5, int):
                k5 = 0
            return (k1, -k2, k3, -k4, -k5, i)
        elif st in 'Q':
            k2 = safeint(job.get('spri','999999'))
            k3 = safeint(job.get('Priority','0'))
            k4 = safeint(job.get('Resource_List.nodect','0'))
            k5 = clocktosecs(job.get('Resource_List.walltime',''))
            if not isinstance(k5, int):
                k5 = 0
            (s, p, _, a, _) = parse_jobid(job.get('id','1.unknown'))
            k6 = p
            k7 = safeint(s)
            k8 = safeint(a.strip('[]') if a else '0')
            return (k1, k2, -k3, -k4, -k5, k6, k7, k8, i)
        (s, p, _, a, _) = parse_jobid(job.get('id','1.unknown'))
        k2 = p
        k3 = safeint(s)
        k4 = safeint(a.strip('[]') if a else '0')
        return (k1, k2, k3, k4, i)
    tags = sorted(range(len(info)), key=cmpf)
    # Display info
    rows = []
    for jobi in tags:
        job = info[jobi]
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, job))
        rows.append(row)
    if rows:
        new_section()
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        lines = layout.layout(cfg, rows, show_hdr=show_hdr)
        hdr_count = len(lines) - len(rows)
        i = 0
        for line in lines:
            print(line.rstrip())
            jobi = i - hdr_count
            if jobi >= 0 and args.n:
                t = info[jobi].get('exec_host', None)
                if t:
                    print("  ", t)
            if jobi >= 0 and args.s:
                t = info[jobi].get('comment', None)
                if t:
                    if len(t) > 76:
                        t = t[:73] + '...'
                    print("  ", t)
            i += 1
    return 1 if errcnt else 0

def display_queues(args, fmtr):
    '''Output info about queues

    For each queue, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W

    cfg = layout.Config()
    idx = 0
    state_count_idx = -1
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, ident=fld['name'], **fld['format'])
        if fld['func'] == 'fmt_state_count':
            state_count_idx = idx
        idx += 1
    rows = []
    info = []
    # Get info about queues
    if args.things == None or len(args.things) == 0:
        conn = ifl.pbs_connect('')
        if conn < 0:
            print("Cannot connect to PBS server: %s" %
                   os.strerror(ifl.get_pbs_errno()),
                    file = sys.stderr)
            return 1
        bs = ifl.pbs_statque(conn, '', fmtr.atl, None)
        ifl.pbs_disconnect(conn)
        info.extend(bs)
    else:
        prev = None
        conn = -1
        for thing in args.things:
            parts = thing.split('@')
            if len(parts) < 2:
                parts.append('')
            (qname, svr) = parts[0:2]
            if svr != prev:
                if conn != -1:
                    ifl.pbs_disconnect(conn)
                conn = ifl.pbs_connect(svr)
                if conn == -1:
                    print("Cannot connect to PBS server %s: %s" %
                          (svr, os.errno(ifl.get_pbs_errno())),
                          file = sys.stderr)
                    prev = None
                    continue
                prev = svr
            bs = ifl.pbs_statque(conn, qname, fmtr.atl, None)
            if len(bs) == 0:
                continue
            info.extend(bs)
        if conn != -1:
            ifl.pbs_disconnect(conn)
    # Deal with state_count field by patching field title and
    # adding 'pretty_sc' attribute to each server
    if state_count_idx >= 0:
        scounts = pretty_state_counts(info)
        fs = cfg.config[state_count_idx]
        fs.title[1] = scounts[0]
        idx = 1
        for svr in info:
            svr['pretty_sc'] = scounts[idx]
            idx += 1
    for svr in info:
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, svr))
        rows.append(row)
    if rows:
        new_section()
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        res = layout.layout(cfg, rows, show_hdr=show_hdr)
        print('\n'.join([x.rstrip() for x in res]))
    return 0

def display_servers(args, fmtr):
    '''Output info about servers

    For each server, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W

    cfg = layout.Config()
    idx = 0
    state_count_idx = -1
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, ident=fld['name'], **fld['format'])
        if fld['func'] == 'fmt_state_count':
            state_count_idx = idx
        idx += 1
    rows = []
    info = []
    # Get info about servers
    if args.things == None or len(args.things) == 0:
        conn = ifl.pbs_connect('')
        if conn < 0:
            print("Cannot connect to PBS server: %s" %
                    os.strerror(ifl.get_pbs_errno()),
                    file = sys.stderr)
            return 1
        bs = ifl.pbs_statserver(conn, fmtr.atl, None)
        ifl.pbs_disconnect(conn)
        info.extend(bs)
    else:
        prev = None
        conn = -1
        for thing in args.things:
            if thing != prev:
                if conn != -1:
                    ifl.pbs_disconnect(conn)
                conn = ifl.pbs_connect(thing)
                if conn == -1:
                    print("Cannot connect to PBS server %s: %s" %
                          (thing, os.strerror(ifl.get_pbs_errno())),
                          file = sys.stderr)
                    prev = None
                    continue
                prev = thing
            bs = ifl.pbs_statserver(conn, fmtr.atl, None)
            if len(bs) == 0:
                continue
            info.extend(bs)
        if conn != -1:
            ifl.pbs_disconnect(conn)
    # Deal with state_count field by patching field title and
    # adding 'pretty_sc' attribute to each server
    if state_count_idx >= 0:
        scounts = pretty_state_counts(info)
        fs = cfg.config[state_count_idx]
        fs.title[1] = scounts[0]
        idx = 1
        for svr in info:
            svr['pretty_sc'] = scounts[idx]
            idx += 1
    for svr in info:
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, svr))
        rows.append(row)
    if rows:
        new_section()
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        res = layout.layout(cfg, rows, show_hdr=show_hdr)
        print('\n'.join([x.rstrip() for x in res]))
    return 0

def cache_server(server, conn):
    '''Cache info about a server

    Args:
        server = server name
        conn = PBS connection to server
    Exit:
        Info about server saved in gserver_info hash
    '''
    global gserver_info, gdebug
    sname = server.split('.')[0]
    if sname in gserver_info:
        return gserver_info[sname]
    bu = BatchUtils()
    bs = file_to_stat(sname, 'server')
    if bs is None:
        bs = ifl.pbs_statserver(conn, None, None)
    info = bs[0]
    gserver_info[sname] = info
    if info == None:
        return info
    # Get reservation list
    atrs = ['reserve_end', 'reserve_start']
    resv_info = file_to_stat(sname, 'resvs', atrs)
    if resv_info == None:
        atrl = bu.list_to_attrl(atrs)
        resv_info = ifl.pbs_statresv(conn, None, atrl, None)
    info['resv_info'] = resv_info
    return info

def cache_shares(server):
    '''Cache share info for server

    Args:
        server = server name
    '''
    global gshare_data, ghostname, ghostnameshort
    sname = server.split('.')[0]
    if sname in gshare_data:
        # Already cached, done
        return
    # Try various places to locate file
    pbshome = pbs_conf.pbs_home_path
    syspath = os.path.join(pbshome, 'sched_priv', 'sortedjobs')
    if sname == ghostnameshort:
        # Running on server host, get file directly
        try:
            with open(syspath) as f:
                data = f.read()
        except:
            data = None
    else:
        # Look for the file in various places
        for d in ( '/home1', '/home', '/u' ):
            fname = os.path.join(d, 'pbs_status', sname)
            if os.path.exists(fname):
                break
            fname = os.path.join(d, 'pbs_status', server)
            if os.path.exists(fname):
                break
        else:
            fname = None
        if fname:
            try:
                with open(fname) as f:
                    data = f.read()
            except:
                data = None
        else:
            data = None
    # Cache whatever results we have
    gshare_data[server] = data
    if server != sname:
        gshare_data[sname] = data

def display_server_hdr(server, conn, args, opts_W):
    '''Display info about server

    Show summary information about a server (before the display
    of jobs on that server).

    Args:
        server = server name
        conn = connection index of server
        args = parsed command line arguments
        opts_W = -W options
    '''
    def safeint(x):
        try:
            t = int(x)
        except:
            t = 0
        return t
    sname = server.split('.')[0]
    info = gserver_info[sname]
    new_section()
    in_server_header = True
    current_server = info.get('id', server)
    print(current_server + ':    ', time.asctime(time.localtime()))
    # Create one-line job header
    total_jobs = safeint(info.get('total_jobs', '0'))
    counts = info.get('state_count','')
    comment = info.get('comment')
    scheduling = info.get('scheduling')
    clist = []
    jcnt = 0
    for x in counts.split():
        y = x.split(':')
        if len(y) != 2:
            continue
        clist.append(y[0][0]+':'+y[1])
        jcnt += safeint(y[1])
    done_count = total_jobs - jcnt
    if done_count > 0 and args.x:
        done_string = " + %d finished" % done_count
    else:
        done_string = ''
    plural = 's' if jcnt != 1 else ''
    print(" Server reports %d job%s total (%s)%s" % (jcnt, plural,
            ' '.join(clist), done_string))
    # Add any server comment and scheduler status
    if comment:
        print("\t", comment)
    if scheduling != 'True':
        print("\t+++ Scheduling turned off.")
    # Display info about MoMs
    all_resvs = info.get('resv_info',())
    fmta_init(all_resvs, userexit_interest)
    node_detail = check_W_bool('node_detail')
    default_fields = ['host', 'cpus', 'gpus', 'tasks', 'jobs', 'ninfo']
    if node_detail:
        default_fields = ['host', 'cused', 'cfree', 'gused', 'gfree', 'mused', 'mfree', 'tasks', 'jobs', 'ninfo']
    fmtr = NAS_field_format(default_fields, 'fmta')
    known_fields = gen_field_list_a()
    define_on_the_fly(known_fields, opts_W, 'oa')
    fmtr.known_fields = known_fields
    userexit_add_fields_a(globals(), locals())
    (field_list, attr_set, errs) = fmtr.collect_fields('oa')
    if (errs):
        # Check if should just print list of fields
        if field_list == None:
            print('\n'.join(errs))
            return 0
        print(errs, file = sys.stderr)
    if check_W_bool('node_comments', False):
        attr_set.add('comment')
    # Adjust formatting of selected fields, per -W fmta_xxx values
    fmtr.field_list = field_list
    rc = fmtr.adjust_formats(field_list)
    if rc != True:
        print(rc, file=sys.stderr)
        return 1
    nas_field_format.set_field_vars(opts_W)
    cfg = layout.Config()
    ninfo_idx = -1
    idx = 0
    for fld in field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, ident=fld['name'], **fld['format'])
        if fld['name'] == 'ninfo':
            ninfo_idx = idx
        idx += 1
    # If server is in promising state, collect info about each MoM
    bu = BatchUtils()
    mom_info = info.get('mom_info', None)
    if (mom_info == None):
        state = info.get('server_state','')
        if re.search(r'Scheduling|Active|Idle', state):
            attr_list = (','.join(attr_set)).split(',')
            while '' in attr_list:
                attr_list.remove('')
            atl = None if len(attr_list) == 0 else bu.list_to_attrl(attr_list)
            mom_info = file_to_stat(sname, 'vnodes', attr_list)
            if mom_info is None:
                if conn is not None:
                    mom_info = ifl.pbs_statvnode(conn, None, atl, None)
            # Condense vnode info into natural vnodes if desired
            condense = check_W_bool('condense_vnodes', None)
            if condense == None:
                condense = sname in check_W_str('condense_vnodes').split(',')
            if condense:
                mom_info = condense_vnode_info(mom_info)
        info['mom_info'] = mom_info
    mom_list = []
    for minfo in mom_info:
        mom_name = minfo.get('id')
        if not mom_name:
            continue
        # If interested in specific hosts, skip others
        if host_re and not (host_re.match(mom_name) or \
                host_re.match(minfo.get('host',''))):
            continue
        mom_row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            mom_row.append(func(f, minfo))
        mom_list.append(mom_row)
    userexit_set_server(globals(), locals())
    # Handle summarizing
    nrows = mom_list
    t = check_W_int('node_bin_total', 10)
    if t > 0 and len(nrows) >= t and ninfo_idx >= 0:
        # sort by minfo field
        nrows.sort(key=lambda mom: mom[ninfo_idx])
        node_bin_size = check_W_int('node_bin_size', 2)
        new_rows = []
        start = 0
        match = nrows[start][ninfo_idx]
        # Scan sorted list, collecting nodes with similar info fields.
        # Use dummy last entry to force out final real entries
        for idx in range(len(nrows) + 1):
            mom_row = nrows[idx] if idx < len(nrows) else (['NO_MATCH'] * (ninfo_idx+1))
            info = mom_row[ninfo_idx]
            if info != match:
                count = idx - start
                if count <= node_bin_size:
                    # If fewer similar nodes than node_bin_size, include nodes
                    # directly
                    new_rows.extend(nrows[start:idx])
                else:
                    # Otherwise, summarize nodes into one entry
                    sum_row = summarize_nodes(field_list, nrows[start:idx])
                    new_rows.append(sum_row)
                match = info
                start = idx
        nrows = new_rows
    # Give admin/user one last chance to tweak field values before layout
    userexit_last_chance_a(globals(), locals())
    # Layout result
    if len(nrows) > 0:
        rows = layout.layout(cfg, nrows)
        for r in rows:
            print(' ',r.rstrip())

def display_shares(emap):
    '''Display NAS mission share info

    Args:
        emap = Cached share entity info from sortedjobs file
    '''
    share_opts = check_W_int('shares')
    slist = list()
    # Collect some info from root entry
    item = emap.get('root', None)
    if not item:
        return
    totalalloc = item['gross']
    totalncpus = item['alloc']
    # Visit the saved share data in the original order
    for entity in sorted(emap, key=lambda e:emap[e]['idx']):
        item = emap[entity]
        gross = item['gross']
        net = item['net']
        alloc = item['alloc']
        if gross == -1:
            continue
        if totalalloc > 0:
            sharepct = gross * 100 // totalalloc
        else:
            sharepct = 0
        (exempt, limited, borrow) = [item[x] for x in ('e', 'l', 'b')]
        demand = item['ed'] + item['ld'] + item['bd']
        # Skip entries with nothing to offer
        if gross == 0 and demand == 0:
            continue
        shareuse = limited + borrow
        if totalncpus > 0:
            usepct_str = str(shareuse * 100 // totalncpus)
        else:
            usepct_str = '--'
        avail = alloc - shareuse
        if avail < 0:
            borrowed = shareuse - alloc
            avail = 0
        else:
            borrowed = 0
        if alloc > 0:
            t = float(shareuse) / float(alloc)
            ratio_str = '%.2f' % t
        else:
            ratio_str = '--'
        if share_opts & 2:
            # TODO
            backlog = 0
            backlog_str = secstoclock(backlog, False, check_W_bool('human'))
        if entity == 'root':
            entity_str = 'Overall'
        else:
            entity_str = ' ' + entity
        sinfo = [entity_str, str(sharepct), usepct_str, str(alloc), str(exempt),
            str(shareuse), str(avail), str(borrowed), ratio_str, str(demand)]
        if share_opts & 2:
            sinfo.append(backlog_str)
        slist.append(sinfo)
    # Unlikely, but there might be nothing to display
    if len(slist) == 0:
        return
    # Construct formatter
    c = layout.Config()
    c.add_field('Group')
    c.add_field('Share%', hj = 'r')
    c.add_field('Use%', hj = 'r')
    c.add_field('Share', hj = 'r')
    c.add_field('Exempt', hj = 'r')
    c.add_field('Use', hj = 'r')
    c.add_field('Avail', hj = 'r')
    c.add_field('Borrowed', hj = 'r')
    c.add_field('Ratio', hj = 'r')
    c.add_field('Waiting', hj = 'r')
    if share_opts & 2:
        c.add_field('Backlog', hj = 'r')
    # Format and print info
    new_section()
    show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
    rows = layout.layout(c, slist, 0, show_hdr)
    print('\n'.join([x.rstrip() for x in rows]))
    return

def gen_field_list():
    '''Generate list of known fields for jobs

    Returns: list of field_info dicts for known fields
    The dicts have these key/value pairs
        name: the name of the field
        format: dict suitable for passing to layout.add_field()
        func: name of function to calculate display value
        sources: reservation attributes whose values are needed by func
    '''
    fl = []
    rj = {'hj': 'r'}
    hlrj = {'hj': 'l', 'rj': 'r'}
    fl.append(gen_field('acct', 'Acct', None, 'fmt_by_attr', 'Account_Name'))
    fl.append(gen_field('aoe', 'AOE', None, 'fmt_aoe', 'schedselect'))
    fl.append(gen_field('comment', 'Comment', None, 'fmt_by_attr', 'comment'))
    fl.append(gen_field('cnt', 'Cnt', rj, 'fmt_by_attr', None))
    fl.append(gen_field('cpct', 'Cpct', rj, 'fmt_from_rsrc', 'resources_used', 'cpupercent'))
    fl.append(gen_field('cpus', 'CPUs', rj, 'fmt_from_rsrc', 'Resource_List', 'ncpus'))
    fl.append(gen_field('cput', 'Cput', rj, 'fmt_from_rsrc', 'resources_used', 'cput'))
    fl.append(gen_field('ctime', 'Ctime', None, 'fmt_date', 'ctime'))
    fl.append(gen_field('eff', 'Eff', rj, 'fmt_efficiency', 'resources_used'))
    fl.append(gen_field('elapwallt', ['Elap', 'wallt'], rj, 'fmt_elapsed', 'resources_used etime job_state'))
    fl.append(gen_field('eligtime', ['Elig', 'time'], rj, 'fmt_elig_time', 'etime'))
    fl.append(gen_field('eligwait', ['Elig', 'wait'], rj, 'fmt_duration', 'eligible_time'))
    fl.append(gen_field('estend', ['Est', 'end'], None, 'fmt_est_end', 'job_state stime estimated Resource_List resources_used'))
    fl.append(gen_field('eststart', ['Est', 'start'], rj, 'fmt_future_date', 'estimated', 'start_time'))
    fl.append(gen_field('exechost', 'Exec_host', None, 'fmt_by_attr', 'exec_host'))
    fl.append(gen_field('exitstatus', ['Exit', 'status'], rj, 'fmt_by_attr', 'Exit_status'))
    fl.append(gen_field('gpus', 'GPUs', rj, 'fmt_from_rsrc', 'Resource_List', 'ngpus'))
    fl.append(gen_field('group', 'Group', None, 'fmt_by_attr', 'egroup'))
    fl.append(gen_field('jobid', 'JobID', None, 'fmt_jobid', None))
    fl.append(gen_field('jobname', 'Jobname', None, 'fmt_by_attr', 'Job_Name'))
    fl.append(gen_field('lifetime', 'Life time', rj, 'fmt_lifetime', 'job_state qtime mtime'))
    fl.append(gen_field('maxwallt', ['Max', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'max_walltime'))
    fl.append(gen_field('memory', 'Memory', hlrj, 'fmt_from_rsrc_sz', 'resources_used Resource_List', 'mem'))
    fl.append(gen_field('minwallt', ['Min', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'min_walltime'))
    fl.append(gen_field('mission', 'Mission', None, 'fmt_mission', None))
    fl.append(gen_field('model', 'Model', None, 'fmt_model', 'schedselect'))
    fl.append(gen_field('nds', 'Nds', rj, 'fmt_from_rsrc', 'resources_used Resource_List', 'nodect'))
    fl.append(gen_field('place', 'Place', None, 'fmt_by_name', 'Resource_List'))
    fl.append(gen_field('pmem', 'Pmem', hlrj, 'fmt_from_rsrc', 'resources_used', 'mem'))
    fl.append(gen_field('pri', 'Pri', rj, 'fmt_by_attr', 'Priority'))
    fl.append(gen_field('qtime', 'Qtime', None, 'fmt_date_full', 'qtime'))
    fl.append(gen_field('queue', 'Queue', None, 'fmt_by_attr', 'queue'))
    fl.append(gen_field('rank0', 'Rank0', None, 'fmt_rank0', 'exec_host'))
    fl.append(gen_field('reqid', 'ReqID', None, 'fmt_by_attr', 'id'))
    fl.append(gen_field('reqmem', 'Reqmem', hlrj, 'fmt_from_rsrc_sz', 'Resource_List', 'mem'))
    fl.append(gen_field('remwallt', ['Rem', 'wallt'], rj, 'fmt_remaining', 'Resource_List resources_used job_state'))
    fl.append(gen_field('reqdwallt', ['Req\'d', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'walltime'))
    fl.append(gen_field('runs', 'Runs', rj, 'fmt_by_attr', 'run_count'))
    fl.append(gen_field('s', 'S', None, 'fmt_by_attr', 'job_state'))
    fl.append(gen_field('sessid', 'SessID', rj, 'fmt_by_attr', 'session_id'))
    fl.append(gen_field('seqno', 'SeqNo', None, 'fmt_seqno', None))
    fl.append(gen_field('ss', 'Ss', None, 'fmt_jobstate', 'job_state Hold_Types'))
    fl.append(gen_field('stime', 'Stime', None, 'fmt_date', 'stime'))
    fl.append(gen_field('user', 'User', None, 'fmt_by_attr', 'euser'))
    fl.append(gen_field('vmem', 'Vmem', hlrj, 'fmt_from_rsrc_sz', 'resources_used', 'vmem'))
    return fl

def gen_field_list_B():
    '''Generate field list for server display
    '''
    fl = []
    dr = {'dj': 'r'}
    de = {'df': '='}
    dre = {'dj': 'r', 'df': '='}
    fl.append(gen_field('server_name', ['Server','name'], de, 'fmt_id', None))
    fl.append(gen_field('jm', 'jm', dre, 'fmt_by_attr', 'max_running'))
    fl.append(gen_field('state_count', ['State count', ''], de, 'fmt_state_count', 'state_count'))
    fl.append(gen_field('default_queue', ['Default','queue'], de, 'fmt_by_attr', 'default_queue'))
    fl.append(gen_field('info', 'Info', de, 'fmt_server_info', 'server_state comment scheduling'))
    return fl

def gen_field_list_Q():
    '''Generate field list for queue display
    '''
    fl = []
    rr = {'rj': 'r'}
    de = {'df': '='}
    dre = {'rj': 'r', 'df': '='}
    dle = {'rj': 'l', 'df': '='}
    dfltf = {'hj':'r', 'hs':'/', 'df':'='}
    fl.append(gen_field('q_name', ['Queue','name'], de, 'fmt_id', None))
    fl.append(gen_field('q_ncpus', ['Ncpus','max'], dfltf, 'fmt_from_rsrc',
        'resources_max', 'ncpus'))
    fl.append(gen_field('q_ncpus_def', 'def', dle, 'fmt_from_rsrc',
        'resources_default', 'ncpus'))
    fl.append(gen_field('q_time', ['Time','max'], dfltf, 'fmt_from_rsrc_tm',
        'resources_max', 'walltime'))
    fl.append(gen_field('q_time_def', 'def', dle, 'fmt_from_rsrc_tm',
        'resources_default', 'walltime'))
    fl.append(gen_field('q_jm', 'jm', dre, 'fmt_by_attr', 'max_running'))
    fl.append(gen_field('state_count', ['State count', ''], de, 'fmt_state_count', 'state_count'))
    fl.append(gen_field('q_pr', 'pr', dre, 'fmt_by_attr', 'Priority'))
    fl.append(gen_field('q_info', 'Info', de, 'fmt_queue_info', 'enabled started'))
    return fl

def gen_field_list_a():
    '''Generate field list for -a node display
    '''
    fl = []
    fl.append(gen_field('host', 'Host', {'rj':'lr'}, 'fmta_host', None, 'sum_hosts'))
    fl.append(gen_field('cpus', 'CPUs', {'hj':'r'}, 'fmta_count', 'resources_available', 'ncpus sum'))
    fl.append(gen_field('cused', ['CPUs', 'used'], {'hj':'r', 'hs':'/'}, 'fmta_used', 'resources_assigned', 'ncpus sum'))
    fl.append(gen_field('cfree', 'free', {'hj':'l', 'rj':'r'}, 'fmta_free', 'resources_available resources_assigned', 'ncpus sum'))
    fl.append(gen_field('gpus', 'GPUs', {'hj':'r', 'suppress':True}, 'fmta_count', 'resources_available', 'ngpus sum'))
    fl.append(gen_field('gused', ['GPUs', 'used'], {'hj':'r', 'hs':'/', 'suppress':True}, 'fmta_used', 'resources_assigned', 'ngpus sum'))
    fl.append(gen_field('gfree', ['', 'free'], {'hj':'l', 'rj':'r', 'suppress':True}, 'fmta_free', 'resources_available resources_assigned', 'ngpus sum'))
    fl.append(gen_field('mem', 'Mem', {'hj':'r'}, 'fmta_mem', 'resources_available', 'mem sum_mem'))
    fl.append(gen_field('mused', ['Mem', 'used'], {'hj':'r', 'hs':'/'}, 'fmta_mem', 'resources_assigned', 'mem sum_mem'))
    fl.append(gen_field('mfree', 'free', {'hj':'l', 'rj':'r'}, 'fmta_mfree', 'resources_available resources_assigned', 'mem sum_mem'))
    fl.append(gen_field('state', 'State', None, 'fmt_by_name', 'state', 'const'))
    fl.append(gen_field('tasks', 'Tasks', {'hj':'r'}, 'fmta_tcnt', 'jobs', 'sum'))
    fl.append(gen_field('jobs', 'Jobs',{'hj':'r'}, 'fmta_jcnt', 'jobs', 'sum_jobs'))
    fl.append(gen_field('ninfo', 'Node Info', None, 'fmta_info', 'state comment resources_available partition queue resv', 'const'))
    return fl

def add_server_conn(smap, svr, conn):
    '''Add mappings from server to PBS connection

    Given a server name, look up its fqdn, IP addresses, aliases and
    add them to a mapping from server to connection.

    Args:
        smap = Dictionary mapping names to connections to be updated.
        svr = Server to add
        conn = Connection to associate with server
    Returns:
        None if name lookup failed, else True
    Exit:
        smap updated
    '''
    if svr in smap:
        # Don't replace existing entries with None
        if conn == None:
            return True
    try:
        (hname, aliases, ipaddrs) = socket.gethostbyname_ex(svr)
    except:
        if svr not in smap:
            smap[svr] = None
        return None
    smap[svr] = conn
    smap[hname] = conn
    for x in aliases:
        smap[x] = conn
    for x in ipaddrs:
        smap[x] = conn
    return True

def check_W_bool(name, default=False):
    '''Get boolean value from opts_W

    Args:
        name = nmae of option
        default = value if option not present
    Returns:
        True if option present in opts_W and not set false
        default otherwise
    '''
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        # Option by itself is True
        if wopt == name:
            return True
        # Examine name=value
        if not wopt.startswith(namee):
            continue
        val = wopt[len(namee):].lower()
        if val == 't' or val == 'true' or val == '1':
            return True
        if val == 'f' or val == 'false' or val == '0':
            return False
    return default

def check_W_int(name, default=0):
    '''Get integer value from opts_W

    Args:
        name = name of option
        default = value if option not present
    Returns:
        Integer value of found option
    '''
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        # option by itself gives 1
        if wopt == name:
            return 1
        if not wopt.startswith(namee):
            continue
        # Examine name=value
        val = wopt[len(namee):].lower()
        try:
            return int(val)
        except:
            if val == '': return default
            if val == 't': return 1
            if val == 'f': return 0
    return default

def check_W_str(name, default=''):
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        # Option by itself is default
        if wopt == name:
            return default
        # Examine name=value
        if not wopt.startswith(namee):
            continue
        val = wopt[len(namee):]
        return val
    return default

def condense_vnode_info(nodes):
    '''Sum info for vnodes into their natural vnodes

    That is, assign numeric attributes for the natural vnode to the sums
    of the attributes for the vnodes for the host.

    Args:
        nodes = list of node info dicts
    Returns:
        new version of the list
    '''
    def safeint(s):
        try:
            t = int(s)
        except:
            t = 0
        return t
    def safemem(s):
        '''Return a memory value as a float number of bytes'''
        if isinstance(s, float):
            return s
        t = unsuffix(s)
        return t
    def cmpf(item):
        '''Ugly function to supply to sorted() to sort vnode info

        The goal is for the node names to be sorted into human order,
        which basically means digit portions sort by numeric value
        rather than alphabetically. This routine takes the item id
        and returns a list of alternating strings and integers.
        Special handling is required for vnode names (abc[foo]).
        '''
        name = item['id']
        parts = list()
        flds = name.split('[', 1)
        first_pass = True
        for nm in flds:
            s = 0
            idx = 0
            l = len(nm)
            while idx < l:
                s = idx
                while idx < l:
                    if nm[idx].isdigit():
                        break
                    idx = idx+1
                cpart = nm[s:idx]
                s = idx
                while idx < l:
                    if not nm[idx].isdigit():
                        break
                    idx = idx+1
                npart = nm[s:idx]
                if npart != '':
                    npart = int(npart)
                else:
                    npart = -1
                parts.extend([cpart, npart])
            if first_pass and len(flds) > 1:
                parts.extend(['[', -1])
            first_pass = False
        return parts

    nat_info = None
    nat_name = None
    oddballs = list()
    new_list = list()
    ignore_states = set(['free','job-exclusive','job-busy'])
    for ninfo in sorted(nodes, key=cmpf):
        cur_name = ninfo.get('Mom','').split('.')[0]
        if cur_name != nat_name:
            # New Mom, flush condensed node info to new list
            if nat_info:
                new_list.append(nat_info)
                new_list.extend(oddballs)
            nat_info = ninfo
            nat_name = cur_name
            oddballs = list()
            continue
        # A vnode, check if there is something odd about it
        odd = False
        while True:
            for a in ['queue', 'vntype']:
                if nat_info.get(a,None) != ninfo.get(a,None):
                    odd = True
                    break
            if odd: break
            a = 'state'
            nat = nat_info.get(a)
            cur = ninfo.get(a)
            if nat != cur:
                nats = set(nat.split(','))
                curs = set(cur.split(',')) - ignore_states
                if not curs.issubset(nats):
                    odd = True
            break
        if odd:
            oddballs.append(ninfo)
            continue
        # Condense current vnode into natural node
        for a in ['resources_available', 'resources_assigned']:
            for r in ['mem', 'vmem']:
                z = a+'.'+r
                t = safemem(nat_info.get(z,0.0)) + safemem(ninfo.get(z,0.0))
                nat_info[z] = ensuffix(t, 'K')
            for r in ['ncpus', 'ngpus']:
                z = a+'.'+r
                t = safeint(nat_info.get(z,0)) + safeint(ninfo.get(z,0))
                nat_info[z] = str(t)
        # End of condensing
    if nat_info:
        new_list.append(nat_info)
        new_list.extend(oddballs)
    return new_list

def extract_job_info(server):
    '''Extract NAS-specific info from sorted jobs data

    Using the cached copy of the server's sortedjobs file, squirrel away
    the info for each job, into gNAS_job_data, after appending the index
    of the job in the sorted file (which represents the results of
    scheduler's job sort.

    The lines of interest have the form (tab-separated):

    jobid queue user share_name starve est_start priority ncpus

    Args:
        server = server name
    '''
    global gNAS_job_data, gshare_data

    sname = server.split('.')[0]
    t = gshare_data.get(sname, None)
    if not t:
        return
    idx = 0
    for line in t.split('\n'):
        if line.startswith('#') or line == '':
            # Skip comments and empty lines
            continue
        (jobid, rest) = line.split('\t', 1)
        jobid = jobid.strip()
        gNAS_job_data[jobid] = line + '\t' + str(idx)
        idx += 1

def extract_share_info(server):
    '''Extract share info from sortedjobs data

    We create a dict of dicts for each share entity listed
    Interesting lines have the format
    #A     entity=[class] gross net ncpus inuse leader
    Where entity is the mission name, or a group:user
        gross = allocated share from shares file
        net = gross adjusted by unavailable resources
        ncpus = units currently in use
        inuse = e+ed/l+ld/b+bd
            where e = inuse, but exempt
                l = inuse, subject to share limits
                b = inuse, borrowed from other shares
                d suffix = queued demands of each of the above
        leader = base mission of allocation
    The entry for root is special and reflects overall information.
    Entries with gross == -1 don't have their own allocation, but use
    the allocation given by their leader field.
    E.g.,
        #A              root=   520 0   2   0+0/0+0/0+0 root
        #A               SMD=   500 500 1   0+0/0+0/0+0 SMD
        #A               NAS=   20  20  0   0+0/0+0/1+5 NAS
        #A dtalcott:dtalcott=   -1  0   -1  0+0/0+0/1+5 NAS
    Args:
        server = name of server
    '''
    global gshare_entity_info, gshare_data, verbose

    gshare_entity_info = dict()
    sname = server.split('.')[0]
    t = gshare_data.get(sname, None)
    if not t:
        return
    idx = 0                 # Used later to sort
    for line in t.split('\n'):
        if line == '' or not line.startswith('#A'):
            continue
        flds = line[2:].split('\t')
        if len(flds) != 6:
            if verbose:
                print("Malformed line in sortedjobs file:", line,
                    file=sys.stderr)
            continue
        z = flds[0].split('=')
        if len(z) != 2:
            if verbose:
                print("Malformed share entity in sortedjobs file:", line,
                    file=sys.stderr)
            continue
        entity = z[0].strip()
        cls = z[1].strip()
        key = entity if cls == '' else '<' + cls + '> ' + entity
        try:
            gross = int(flds[1])
            net = int(flds[2])
            alloc = int(flds[3])
            inuse = flds[4]
            leader = flds[5]
        except:
            if verbose:
                print("Bad values in sortedjobs file:", line,
                    file=sys.stderr)
            continue
        mo = re.match(r'(\d+)\+(\d+)/(\d+)\+(\d+)/(\d+)\+(\d+)$', inuse)
        if not mo:
            if verbose:
                print("Bad usage in sortedjobs file:", line,
                    file=sys.stderr)
            continue
        e, ed, l, ld, b, bd = mo.groups()
        item = {'gross': gross, 'net': net, 'alloc': alloc,
            'e': int(e), 'ed': int(ed), 'l': int(l), 'ld': int(ld),
            'b': int(b), 'bd': int(bd),
            'leader': leader, 'idx':idx}
        idx += 1
        gshare_entity_info[key] = item
    return

new_section_called = False
def new_section():
    '''Output blank line

    Print a blank line except before the first call
    '''
    global new_section_called
    if new_section_called:
        print()
    new_section_called = True

def plug_job_info(bs):
    '''Add NAS-specific info to job info

    Args:
        bs = batch status from call to pbs_statjob, etc
    Exit:
        bs updated
    '''
    global gNAS_job_data

    for job in bs:
        jobid = job['id']
        if jobid in gNAS_job_data:
            (jid, queue, user, share, starve, est_start, pri, ncpus, idx) = \
                gNAS_job_data[jobid].split('\t')
            job['Priority'] = pri
            job['share_entity'] = share
            job['spri'] = int(idx)
    return

def pretty_state_counts(ilist):
    '''Convert state info into "pretty" output

    Args:
        ilist = List of dicts with 'state_count' attributes to be beautified
    Returns:
        A list of strings suitable for printing. The first element is a header
        and the remaining are state counts, one for each element in ilist.
    '''
    sclist = []
    maxsn = []
    for info in ilist:
        state_count = info.get('state_count', '')
        state_names = []
        state_cnts = []
        for one_count in state_count.split():
            mo = re.match(r'([A-Z])\w+:(\d+)', one_count)
            if mo:
                state_names.append(mo.group(1))
                state_cnts.append(mo.group(2))
        if len(state_names) > len(maxsn):
            maxsn = state_names
        sclist.append(state_cnts)
    # Deal with no data
    if len(maxsn) < 1:
        return ['--'] * (len(ilist) + 1)
    # Now, use layout to make into uniform size for all elements of ilist
    cfg = layout.Config()
    idx = 0
    for sn in maxsn:
        idx += 1
        s = '/' if idx < len(maxsn) else ''
        cfg.add_field(sn, hf='_', hj='r', hs=s, df='')
    scrows = layout.layout(cfg, sclist)
    return scrows

def summarize_nodes(flist, nlist):
    '''Produce one line summary of multiple nodes

    Args:
        fmtr = formatter used to create nlist entries
        nlist = list of node entries, where each entry is a list of
            field values
    '''
    def safeint(x):
        try:
            t = int(x)
        except:
            t = 0
        return t
    # Initialize result row
    new_row = []
    for idx in range(len(flist)):
    # Summarize each field appropriately
        opt = flist[idx]['opt']
        if 'sum' in opt:
            total = 0
            for mom_row in nlist:
                total += safeint(mom_row[idx])
            fldval = str(total)
            if total == 0 and 'squash0' in opt:
                fldval = '--'
        elif 'sum_mem' in opt:
            total = 0
            for mom_row in nlist:
                t = mom_row[idx]
                total += unsuffix(t) if t != '--' else 0.0
            fldval = ensuffix(total)
        elif 'sum_jobs' in opt:
            total = 0
            for mom_row in nlist:
                total += safeint(mom_row[idx])
            # Because jobs might be running on multiple hosts, the
            # only totals that can be reported accurately are 0 and 1
            fldval = str(total) if total <= 1 else ">1"
        elif 'sum_hosts' in opt:
            t = [x[x.find('=')+1:] for x in opt if x.startswith('unit=')]
            unit = 'host' if len(t) == 0 else t[0]
            hcount = len(nlist)
            fldval = ' ' + str(hcount) + ' ' + unit + ('s' if hcount != 1 else ' ')
        elif 'const' in opt:
            fldval = nlist[0][idx]
        else:
            fldval = '--'
        new_row.append(fldval)
    return new_row

if __name__ == '__main__':
    sys.exit(main())

# vi:ts=4:sw=4:expandtab
