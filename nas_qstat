#!/PBS/bin/pbs_python
#Author:dtalcott
#Purpose:Python equivalent of qstat, but with options for how
#Purpose:to display the output.
#Purpose:Use --help for details.
from __future__ import print_function

import sys
import os
import argparse
import re
import subprocess
import socket
import time

PBS_EXEC = os.environ.get('PBS_EXEC', '/PBS')
sys.path.append(os.path.join(PBS_EXEC, 'lib', 'site'))

import pbs_ifl as ifl
from nas_utils import BatchUtils
from nas_pbsutil import *
import nas_layout as layout
import nas_field_format
from nas_field_format import NAS_field_format,gen_field,clocktosecs

long_desc = '''Display information about jobs, queues, or servers

This command displays information about PBS jobs, queues, or servers,
writing the status to standard output. It is similar to PBS's qstat, but
provides more options for selecting and formatting the output.
'''

args = None
gNAS = False
gNow = time.time()
gserver_info = dict()
host_re = None
opts_W = list()
pbs_conf = ifl.cvar.pbs_conf
verbose = 0

def main():
    global verbose, args, opts_W, host_re
    # Don't catch any signals (so no ugly tracebacks on Ctrl-C).
    for i in range(1, 30):
        try:
            signal.signal(i, signal.SIG_DFL)
        except:
            pass
    prog = sys.argv[0].split('/')[-1]
    parser = argparse.ArgumentParser(description=long_desc, prog=prog,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    thing_type = parser.add_mutually_exclusive_group()
    parser.add_argument('--version', action='version',
        version='%(prog)s $Id:$')
    thing_type.add_argument('-B', default=False, action='store_true',
        help='Display information for servers')
    parser.add_argument('-G', default='b', action='store_const',
        dest='size_units', const='G',
        help='Display sizes in gigabytes')
    parser.add_argument('-H', default=False, action='store_true',
        help='Select only finished or moved jobs')
    parser.add_argument('-J', default=False, action='store_true',
        help='Display status information for job arrays')
    parser.add_argument('-M', default='b', action='store_const',
        dest='size_units', const='M',
        help='Display sizes in 8 byte megawords')
    thing_type.add_argument('-Q', default=False, action='store_true',
        help='Display information for queues')
    parser.add_argument('-W', action='append', metavar='display option',
        help='Options customizing field selection and display.')
    parser.add_argument('-a', default=False, action='store_true',
        help='Display all jobs, in alternate format')
    parser.add_argument('-i', default=False, action='store_true',
        help='Select queued, held, or waiting jobs')
    parser.add_argument('-n', default=False, action='store_true',
        help='Include exec_host information')
    parser.add_argument('-r', default=False, action='store_true',
        help='Select running or suspended jobs')
    parser.add_argument('-s', default=False, action='store_true',
        help='Include job comment')
    parser.add_argument('-t', default=False, action='store_true',
        help='Display status information for jobs, job_arrays, and subjobs')
    parser.add_argument('-u',
        help='Display only jobs from this user')
    parser.add_argument('--verbose', '-v', default=0, action='count',
        help='Increase debugging verbosity')
    parser.add_argument('-x', default=False, action='store_true',
        help='Include finished and moved jobs')
    parser.add_argument('things', nargs='*',
        help='Jobs, queues, or servers to status')

    args = parser.parse_args()
    verbose = args.verbose

    if (ifl.pbs_loadconf(0) == 0):
        print("Cannot get PBS configuration information", file=sys.stderr)
        return 1

    # Look at -B, -Q, and -a options to decide on default list of fields
    if args.Q:
        default_fields = ['q_name', 'q_ncpus', 'q_ncpus_def', 'q_time', 'q_time_def', 'q_jm', 'state_count', 'q_pr', 'q_info']
        kf = gen_field_list_Q()
    elif args.B:
        default_fields = ['server_name', 'jm', 'state_count', 'default_queue', 'info']
        kf = gen_field_list_B()
    else:
        default_fields = ['jobid', 'user', 'queue', 'jobname', 'tsk', 'nds',
            'reqdwallt', 's', 'elapwallt', 'eff']
        kf = gen_field_list()
        if args.verbose > 2:
            # Show titles of known fields
            l = []
            for x in kf:
                t = x['title']
                l.append(t if isinstance(t, str) else ' '.join(t))
            print('Known field titles', ', '.join(l))

    # Build list of known fields
    opts_W = args.W
    if opts_W is None:
        opts_W = list()
    # Make units for sizes available in opt_W
    opts_W.append(args.size_units)
    # Load possible user or system overrides
    more_code = load_sysexits('qstat')
    if more_code:
        prog = compile(more_code, 'sysexit code', 'exec')
        exec(prog, globals(), locals())
    sysexit_post_opts(globals(), locals())
    fmtr = NAS_field_format(default_fields, verbose, opts_W)
    fmtr.known_fields = kf
    sysexit_add_fields(globals(), locals())

    # Handle -W options
    # First, collect list of fields of interest and which PBS attributes
    # hold the values for those fields
    (field_list, attr_list, errs) = fmtr.collect_fields()
    if (errs):
        print(errs, file = sys.stderr)
    # Adjust formatting of selected fields, per -W fmt_xxx values
    rc = fmtr.adjust_formats(field_list)
    if rc != True:
        print(rc, file=sys.stderr)
        return 1
    fmtr.field_list = field_list
    # Set formatting globals from cmd line args
    nas_field_format.set_field_vars(opts_W)
    # Decide if will be filtering based on execution host
    host_patt = check_W_str('host')
    if host_patt == None:
        host_patt = check_W_str('hosts')
    if host_patt:
        host_re = re.compile(r'\b('+host_patt.replace(',','|')+r')\b', re.I)
    else:
        host_re = None
    if host_re:
        # If we are filtering by host, make sure we ask for exec_host
        if not 'exec_host' in attr_list:
            attr_list.add('exec_host')
    bu = BatchUtils()
    t = (','.join(attr_list)).split(',')
    atl = bu.list_to_attrl(t)
    fmtr.atl = atl

    # Last, get and display requested information
    if args.Q:
        rc = display_queues(args, fmtr)
    elif args.B:
        rc = display_servers(args, fmtr)
    else:
        rc = display_jobs(args, fmtr)
    return rc

def display_jobs(args, fmtr):
    '''Output job info

    For each job, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W, host_re

    # Examine options to set selection and extend attributes
    selects = dict()
    extend = set()
    if args.i:
        selects['job_state'] = 'HQTW'
    if args.r or host_re:
        selects['job_state'] = 'BERSU'
    if args.H:
        selects['job_state'] = 'FMX'
        extend.add('x')
    if args.t:
        extend.add('t')
    if args.x:
        extend.add('x')
    if args.u:
        selects['euser'] = args.u
    if args.J:
        selects['array'] = 'True'
    extend = ''.join(extend)

    alt_disp = True if args.a else False

    # Build base layout
    cfg = layout.Config()
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, **fld['format'])

    # Gather data from server
    server_conn = {'': None, None: None}
    rows = []
    bu = BatchUtils()
    sel_attr = bu.dict_to_attropl(selects, ifl.EQ)
    things = args.things
    errcnt = 0
    if len(things) == 0:
        # No destinations, ask for jobs at default server
        things.append('@' + pbs_conf.pbs_server_name)
    # There can be three types of objects to get job info for:
    # individual jobs, queues, and servers. Distinguish them
    info = []
    idx = 0
    while idx < len(things):
        thing = things[idx].strip()
        idx += 1
        seq_num = None
        is_jobs = False
        if thing[0] not in '123456789':
            # Server or queue
            if thing[0] is '@':
                queue = None
                names = [thing]
                current_server = thing[1:]
            else:
                t = thing.split('@')
                queue = t[0]
                names = [queue]
                current_server = t[1] if len(t) > 1 else None
        else:
            is_jobs = True
            # Job id
            try:
                (seq_num, parent_server, current_server, array_idx, _) = \
                    parse_jobid(thing)
            except:
                print("Unrecognized destination: %s" % thing,
                    file = sys.stderr)
                errcnt += 1
                continue
            # Collect sequence of jobids at same server into one list.
            names = []
            jobid = seq_num
            if not parent_server:
                if current_server:
                    parent_server = current_server
                else:
                    parent_server = pbs_conf.pbs_server_name
            if array_idx:
                jobid += array_idx
            jobid += '.' + parent_server
            add_server_conn(server_conn, parent_server, None)
            if current_server and current_server not in server_conn:
                conn = ifl.pbs_connect(current_server)
                add_server_conn(server_conn, current_server, conn)
            names.append(jobid)
            prev_conn = server_conn[current_server]
            # Examine next entry to see if more jobids
            while idx < len(things):
                peek = things[idx]
                if peek[0] not in '123456789':
                    break
                try:
                    (s, p, c, a, _) = parse_jobid(peek)
                except:
                    c = None
                # Detect change of server
                if server_conn.get(c, -2) != prev_conn:
                    break
                jobid = s
                if a:
                    jobid += a
                if not p:
                    if c:
                        p = current_server
                    else:
                        p = pbs_conf.pbs_server_name
                jobid += '.' + p
                names.append(jobid)
                idx += 1
        # Now, issue query to current_server
        if current_server == None:
            current_server = pbs_conf.pbs_server_name
        conn = server_conn.get(current_server, None)
        if conn == None:
            conn = ifl.pbs_connect(current_server)
            add_server_conn(server_conn, current_server, conn)
            if conn < 0:
                print("Cannot connect to PBS server %s: %d" % \
                    (current_server, ifl.pbs_geterrmsg(ifl.pbs_Errno())),
                    file = sys.stderr)
                errcnt += 1
                continue
        if conn == -1:
            # Known bad server name, skip
            continue
        # Display server header, if requested
        if alt_disp:
            cache_server(current_server, conn)
            display_server_hdr(current_server, args, opts_W)
        # Get info for selected jobs
        if sel_attr:
            bs = ifl.pbs_selstat(conn, sel_attr, fmtr.atl, extend)
        else:
            namelist = ','.join(names)
            bs = ifl.pbs_statjob(conn, namelist, fmtr.atl, extend)
        err = ifl.pbs_Errno()
        if err:
            errcnt += 1
            errmsg = ifl.pbs_geterrmsg(conn)
            if errmsg == None or errmsg == '':
                errmsg = "error %d" % err
            errmsg += ': ' + namelist
            print(errmsg,
                file = sys.stderr)
            continue
        # If interested only in jobs on given host, filter the list
        if host_re:
            newbs = []
            for job in bs:
                hosts = job.get('exec_host')
                if not hosts:
                    continue
                if not host_re.search(hosts):
                    continue
                newbs.append(job)
            bs = newbs
        if sel_attr and names and is_jobs:
            # You cannot specify a list of names to the pbs_selstat()
            # call, so we have to filter the results ourselves when
            # explicit request ID were given.
            newbs = []
            name_set = set(names)
            found = set()
            for job in bs:
                jobid = job['id']
                if jobid in name_set:
                    found.add(jobid)
                    newbs.append(job)
            bs = newbs
            missing = name_set.difference(found)
            if missing:
                print("Excluded Job Id%s:" % ('' if len(missing) == 1 else 's'),\
                    ' '.join(missing), \
                    file = sys.stderr)
        if bs:
            info.extend(bs)
        names = []
        # End of idx loop
        # End of null things test
    # Close server connections
    for conn in set(server_conn.values()):
        if conn != None and conn != -1:
            ifl.pbs_disconnect(conn)
    # Tag sort job list
    def cmpf(i):
        def safeint(x):
            try:
                t = int(x)
            except:
                t = 0
            return t
        job = info[i]
        st = job.get('job_state','?')
        k1 = 'BRQHWTEX'.find(st)
        if st in 'BR':
            k2 = safeint(job.get('Priority','0'))
            k3 = job.get('queue','')
            k4 = safeint(job.get('Resource_List.nodect','0'))
            k4 = safeint(job.get('Resource_List.ncpus','0'))
            k5 = clocktosecs(job.get('Resource_List.walltime',''))
            if not isinstance(k5, int):
                k5 = 0
            return (k1, -k2, k3, -k4, -k5, i)
        elif st in 'Q':
            k2 = safeint(job.get('spri','0'))
            k3 = safeint(job.get('Priority','0'))
            k4 = safeint(job.get('Resource_List.nodect','0'))
            k5 = clocktosecs(job.get('Resource_List.walltime',''))
            if not isinstance(k5, int):
                k5 = 0
            (s, p, _, a, _) = parse_jobid(job.get('id','1.unknown'))
            k6 = p
            k7 = safeint(s)
            k8 = safeint(a.strip('[]') if a else '0')
            return (k1, -k2, -k3, -k4, -k5, k6, k7, k8, i)
        (s, p, _, a, _) = parse_jobid(job.get('id','1.unknown'))
        k2 = p
        k3 = safeint(s)
        k4 = safeint(a.strip('[]') if a else '0')
        return (k1, k2, k3, k4, i)
    tags = sorted(range(len(info)), key=cmpf)
    # Display info
    for jobi in tags:
        job = info[jobi]
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, job, opts_W))
        rows.append(row)
    if rows:
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        lines = layout.layout(cfg, rows, show_hdr=show_hdr)
        for line in lines:
            print(line.rstrip())
    return 1 if errcnt else 0

def display_queues(args, fmtr):
    '''Output info about queues

    For each queue, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W

    cfg = layout.Config()
    idx = 0
    state_count_idx = -1
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, **fld['format'])
        if fld['func'] == 'fmt_state_count':
            state_count_idx = idx
        idx += 1
    rows = []
    info = []
    # Get info about queues
    if args.things == None or len(args.things) == 0:
        conn = ifl.pbs_connect('')
        if conn < 0:
            print("Cannot connect to PBS server: %s" % ifl.pbs_Errno(),
                    file = sys.stderr)
            return 1
        bs = ifl.pbs_statque(conn, '', fmtr.atl, None)
        ifl.pbs_disconnect(conn)
        info.extend(bs)
    else:
        prev = None
        conn = -1
        for thing in args.things:
            parts = thing.split('@')
            if len(parts) < 2:
                parts.append('')
            (qname, svr) = parts[0:2]
            if svr != prev:
                if conn != -1:
                    ifl.pbs_disconnect(conn)
                conn = ifl.pbs_connect(svr)
                if conn == -1:
                    print("Cannot connect to PBS server %s: %s" %
                        (svr, ifl.pbs_Errno()), file = sys.stderr)
                    prev = None
                    continue
                prev = svr
            bs = ifl.pbs_statque(conn, qname, fmtr.atl, None)
            if len(bs) == 0:
                continue
            info.extend(bs)
        if conn != -1:
            ifl.pbs_disconnect(conn)
    # Deal with state_count field by patching field title and
    # adding 'pretty_sc' attribute to each server
    if state_count_idx >= 0:
        scounts = pretty_state_counts(info)
        fs = cfg.config[state_count_idx]
        fs.title[1] = scounts[0]
        idx = 1
        for svr in info:
            svr['pretty_sc'] = scounts[idx]
            idx += 1
    for svr in info:
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, svr, opts_W))
        rows.append(row)
    if rows:
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        res = layout.layout(cfg, rows, show_hdr=show_hdr)
        print('\n'.join([x.rstrip() for x in res]))
    return 0

def display_servers(args, fmtr):
    '''Output info about servers

    For each server, generate a list of display values for each
    selected field. Collect those lists into a list and pass it to
    layout for display.
    Args:
        args = result from argparse of command line
        fmtr = field formatter object
    Returns: 0 on success
    '''
    global opts_W

    cfg = layout.Config()
    idx = 0
    state_count_idx = -1
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        cfg.add_field(title, **fld['format'])
        if fld['func'] == 'fmt_state_count':
            state_count_idx = idx
        idx += 1
    rows = []
    info = []
    # Get info about servers
    if args.things == None or len(args.things) == 0:
        conn = ifl.pbs_connect('')
        if conn < 0:
            print("Cannot connect to PBS server: %s" % ifl.pbs_Errno(),
                    file = sys.stderr)
            return 1
        bs = ifl.pbs_statserver(conn, fmtr.atl, None)
        ifl.pbs_disconnect(conn)
        info.extend(bs)
    else:
        prev = None
        conn = -1
        for thing in args.things:
            if thing != prev:
                if conn != -1:
                    ifl.pbs_disconnect(conn)
                conn = ifl.pbs_connect(thing)
                if conn == -1:
                    print("Cannot connect to PBS server %s: %s" %
                        (thing, ifl.pbs_Errno()), file = sys.stderr)
                    prev = None
                    continue
                prev = thing
            bs = ifl.pbs_statserver(conn, fmtr.atl, None)
            if len(bs) == 0:
                continue
            info.extend(bs)
        if conn != -1:
            ifl.pbs_disconnect(conn)
    # Deal with state_count field by patching field title and
    # adding 'pretty_sc' attribute to each server
    if state_count_idx >= 0:
        scounts = pretty_state_counts(info)
        fs = cfg.config[state_count_idx]
        fs.title[1] = scounts[0]
        idx = 1
        for svr in info:
            svr['pretty_sc'] = scounts[idx]
            idx += 1
    for svr in info:
        row = list()
        for f in fmtr.field_list:
            func = getattr(nas_field_format, f['func'])
            row.append(func(f, svr, opts_W))
        rows.append(row)
    if rows:
        show_hdr = '-h' not in opts_W and 'noheader' not in opts_W
        res = layout.layout(cfg, rows, show_hdr=show_hdr)
        print('\n'.join([x.rstrip() for x in res]))
    return 0

def cache_server(server, conn):
    '''Cache info about a server

    Args:
        server = server name
        conn = PBS connection to server
    Exit:
        Info about server saved in gserver_info hash
    '''
    global gserver_info
    sname = server.split('.')[0]
    if sname in gserver_info:
        return gserver_info[sname]
    bu = BatchUtils()
    bs = ifl.pbs_statserver(conn, None, None)
    info = bs[0]
    gserver_info[sname] = info
    if info == None:
        return info
    # If server is in promising state, collect more info
    state = info.get('server_state','')
    if not re.search(r'Scheduling|Active|Idle', state):
        info['mom_info'] = list()
        return info
    atrs = ['jobs', 'partition', 'queue', 'resv', 'state',
        'resources_available', 'resources_assigned']
    if check_W_bool('node_comments', False):
        atrs.append('comment')
    atrl = bu.list_to_attrl(atrs)
    mom_info = ifl.pbs_statvnode(conn, None, atrl, None)
    info['mom_info'] = mom_info
    atrs = ['reserve_end', 'reserve_start']
    atrl = bu.list_to_attrl(atrs)
    resv_info = ifl.pbs_statresv(conn, None, atrl, None)
    info['resv_info'] = resv_info
    return info

def display_server_hdr(server, args, opts_W):
    '''Display info about server

    Show summary information about a server (before the display
    of jobs on that server).

    Args:
        server = server name
        args = parsed command line arguments
        opts_W = -W options
    '''
    def safeint(x):
        try:
            t = int(x)
        except:
            t = 0
        return t
    from nas_field_format import unsuffix, ensuffix
    sname = server.split('.')[0]
    info = gserver_info[sname]
    print(server + ':    ', time.asctime(time.localtime()))
    # Create one-line job header
    total_jobs = safeint(info.get('total_jobs', '0'))
    counts = info.get('state_count','')
    comment = info.get('comment')
    scheduling = info.get('scheduling')
    clist = []
    jcnt = 0
    for x in counts.split():
        y = x.split(':')
        if len(y) != 2:
            continue
        clist.append(y[0][0]+':'+y[1])
        jcnt += safeint(y[1])
    done_count = total_jobs - jcnt
    if done_count > 0 and args.x:
        done_string = " + %d finished" % done_count
    else:
        done_string = ''
    plural = 's' if jcnt != 1 else ''
    print(" Server reports %d job%s total (%s)%s" % (jcnt, plural,
            ' '.join(clist), done_string))
    # Add any server comment and scheduler status
    if comment:
        print("\t", comment)
    if scheduling != 'True':
        print("\t+++ Scheduling turned off.")
    all_resvs = info.get('resv_info',())
    # Collect info about each MoM
    mom_list = []
    for minfo in info.get('mom_info',()):
        mom_name = minfo.get('id')
        if not mom_name:
            continue
        if host_re and not (host_re.match(mom_name) or \
                host_re.match(minfo.get('host',''))):
            continue
        cpus_tot = safeint(minfo.get('resources_available.ncpus'))
        cpus_used = safeint(minfo.get('resources_assigned.ncpus'))
        cpus_free = cpus_tot - cpus_used
        mem_tot = unsuffix(minfo.get('resources_available.mem','0'))
        mem_used = unsuffix(minfo.get('resources_assigned.mem','0'))
        mem_free = mem_tot - mem_used
        jobs = minfo.get('jobs','')
        jset = set()
        task_cnt = 0
        for x in jobs.split(','):
            if x == '':
                continue
            t = x.find('/')
            x = x[:t] if t > -1 else x
            jset.add(x)
            task_cnt += 1
        job_cnt = len(jset)
        comment = minfo.get('comment', '')
        model = minfo.get('resources_available.model','')
        partition = minfo.get('partition', '')
        queue = minfo.get('queue', '')
        resvs = [x.strip() for x in minfo.get('resv', '').split(',')]
        state = minfo.get('state', '')
        # Look for interesting info about MoM
        interest = []
        if queue != '':
            interest.append('q=' + queue)
        if partition != '':
            interest.append('p=' + partition)
        # Some NAS only tweaks
        if gNAS and 'model' in opts_W:
            t = minfo.get('resources_available.bigmem')
            if t == 'True':
                interest[0:0] = ['bigmem']
            t = minfo.get('resources_available.gpu')
            if t:
                interest[0:0] = [t]
            if model != '':
                interest[0:0] = [model]
        # Simplify state string
        t = "" if 'free' in state else "in-use"
        state = state.replace(',', ' ')
        new_states = []
        is_down = False
        is_offline = False
        for ss in state.split(' '):
            if ss in ['job-exclusive', 'job-busy']:
                new_states.append(t)
            elif ss == 'down':
                is_down = True
            elif ss == 'offline':
                is_offline = True
            elif ss in ['Stale', 'state-unknown', 'free', '<various>']:
                pass
            else:
                new_states.append(ss)
        if is_down:
            new_states[0:0] = ['down']
        if is_offline:
            new_states[0:0] = ['offline']
        state = ' '.join(new_states)
        # Include state in interesting info
        if state != '':
            interest.append(state)
        # Remove redundant down info from comment
        if is_down:
            comment = comment.replace('node down: communication closed','')
            comment = comment.replace('  ', ' ')
        # Check for reservations on node
        if resvs and resvs[0] != '':
            r = format_resvs(all_resvs, mom_name, resvs)
            if r:
                interest.append(r)
        if comment:
            interest.append(comment)
        interest = ' '.join(interest)
        mom_row = [mom_name, str(cpus_used), str(cpus_free), ensuffix(mem_used),
            ensuffix(mem_free), str(task_cnt), str(job_cnt), interest]
        mom_list.append(mom_row)
    # TODO Handle summarizing and detail
    zrows = mom_list
    do_binning = len(zrows) >= check_W_int('node_bin_total', 10)
    if do_binning:
        # Sort MoM list by info field (last field)
        zrows.sort(key=lambda mom: mom[-1])
        node_bin_size = check_W_int('node_bin_size', 2)
        new_rows = []
        start = 0
        match = zrows[start][-1]
        # Scan sorted list, collecting nodes with similar info fields.
        # Use dummy last entry to force out final real entries
        for idx in range(len(zrows) + 1):
            mom_row = zrows[idx] if idx < len(zrows) else ['HIGH  VALUE']
            info = mom_row[-1]
            if info != match:
                count = idx - start
                if count < node_bin_size:
                    new_rows.extend(zrows[start:idx])
                else:
                    sum_row = summarize(zrows[start:idx])
                    new_rows.append(sum_row)
                match = info
                start = idx
        zrows = new_rows
    if len(zrows) > 0:
        print()
        fl = []
        fl.append(gen_field('host', 'Host', {'rj':'lr'}, None, None))
        fl.append(gen_field('cpus', ['CPUs', 'used'], {'hj':'r', 'hs':'/'}, None, None))
        fl.append(gen_field('cfree', 'free', {'hj':'l', 'rj':'r'}, None, None))
        fl.append(gen_field('mem', ['Mem', 'used'], {'hj':'r', 'hs':'/'}, None, None))
        fl.append(gen_field('mfree', 'free', {'hj':'l', 'rj':'r'}, None, None))
        fl.append(gen_field('tasks', 'Tasks', {'hj':'r'}, None, None))
        fl.append(gen_field('jobs', 'Jobs',{'hj':'r'}, None, None))
        fl.append(gen_field('info', 'Info', None, None, None))
        dflt_flds = ['host', 'cpus', 'cfree', 'mem', 'mfree', 'tasks', 'jobs', 'info']
        mom_optW = []
        mom_fmtr = NAS_field_format(dflt_flds, verbose, mom_optW)
        mom_fmtr.known_fields = fl
        (field_list, attr_list, errs) = mom_fmtr.collect_fields()
        # TODO
        mom_optW.extend(['fmt_mem=maxw:0 hs: ', 'fmt_mfree=maxw:0'])
        rc = mom_fmtr.adjust_formats(field_list)
        if rc != True:
            print(rc, file=sys.stderr)
        mom_fmtr.field_list = field_list
        c = layout.Config()
        for fld in mom_fmtr.field_list:
            title = fld['title']
            if not title:
                title = fld['name']
            c.add_field(title, **fld['format'])
        rows = layout.layout(c, zrows)
        for r in rows:
            print(' ',r.rstrip())

def gen_field_list():
    '''Generate list of known fields

    Returns: list of field_info dicts for known fields
    The dict have these key/value pairs
        name: the name of the field
        format: dict suitable for passing to layout.add_field()
        func: name of function to calculate display value
        sources: reservation attributes whose values are needed by func
    '''
    fl = []
    rj = {'hj': 'r'}
    hlrj = {'hj': 'l', 'rj': 'r'}
    fl.append(gen_field('acct', 'Acct', None, 'fmt_by_attr', 'Account_Name'))
    fl.append(gen_field('aoe', 'AOE', None, 'fmt_aoe', 'schedselect'))
    fl.append(gen_field('cnt', 'Cnt', rj, 'fmt_by_attr', None))
    fl.append(gen_field('cpct', 'Cpct', rj, 'fmt_from_rsrc', 'resources_used', 'cpupercent'))
    fl.append(gen_field('cput', 'Cput', rj, 'fmt_from_rsrc', 'resources_used', 'cput'))
    fl.append(gen_field('ctime', 'Ctime', None, 'fmt_date', 'ctime'))
    fl.append(gen_field('eff', 'Eff', rj, 'fmt_efficiency', 'resources_used'))
    fl.append(gen_field('elapwallt', ['Elap', 'wallt'], rj, 'fmt_elapsed', 'resources_used etime job_state'))
    fl.append(gen_field('eligtime', ['Elig', 'time'], rj, 'fmt_elig_time', 'etime'))
    fl.append(gen_field('eligwait', ['Elig', 'wait'], rj, 'fmt_duration', 'eligible_time'))
    fl.append(gen_field('estend', ['Est', 'end'], None, 'fmt_est_end', 'job_state stime estimated Resource_List resources_used'))
    fl.append(gen_field('eststart', ['Est', 'start'], rj, 'fmt_future_date', 'estimated', 'start_time'))
    fl.append(gen_field('exitstatus', ['Exit', 'status'], rj, 'fmt_by_attr', 'Exit_status'))
    fl.append(gen_field('group', 'Group', None, 'fmt_by_attr', 'egroup'))
    fl.append(gen_field('jobid', 'JobID', None, 'fmt_jobid', None))
    fl.append(gen_field('jobname', 'Jobname', None, 'fmt_by_attr', 'Job_Name'))
    fl.append(gen_field('lifetime', 'Life time', rj, 'fmt_lifetime', 'job_state qtime mtime'))
    fl.append(gen_field('maxwallt', ['Max', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'max_walltime'))
    fl.append(gen_field('memory', 'Memory', hlrj, 'fmt_from_rsrc_sz', 'resources_used Resource_List', 'mem'))
    fl.append(gen_field('minwallt', ['Min', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'min_walltime'))
    fl.append(gen_field('mission', 'Mission', None, 'fmt_by_attr', 'TODO'))
    fl.append(gen_field('model', 'Model', None, 'fmt_model', 'schedselect'))
    fl.append(gen_field('nds', 'Nds', rj, 'fmt_from_rsrc', 'resources_used Resource_List', 'nodect'))
    fl.append(gen_field('place', 'Place', None, 'fmt_by_name', 'Resource_List'))
    fl.append(gen_field('pmem', 'Pmem', hlrj, 'fmt_from_rsrc', 'resources_used', 'mem'))
    fl.append(gen_field('pri', 'Pri', rj, 'fmt_by_attr', 'Priority'))
    fl.append(gen_field('qtime', 'Qtime', None, 'fmt_date_full', 'qtime'))
    fl.append(gen_field('queue', 'Queue', None, 'fmt_by_attr', 'queue'))
    fl.append(gen_field('rank0', 'Rank0', None, 'fmt_by_attr', 'TODO'))
    fl.append(gen_field('reqid', 'ReqID', None, 'fmt_by_attr', 'id'))
    fl.append(gen_field('reqmem', 'Reqmem', hlrj, 'fmt_from_rsrc_sz', 'Resource_List', 'mem'))
    fl.append(gen_field('remwallt', ['Rem', 'wallt'], rj, 'fmt_remaining', 'Resource_List resources_used job_state'))
    fl.append(gen_field('reqdwallt', ['Req\'d', 'wallt'], rj, 'fmt_from_rsrc_tm', 'Resource_List', 'walltime'))
    fl.append(gen_field('runs', 'Runs', rj, 'fmt_by_attr', 'run_count'))
    fl.append(gen_field('s', 'S', None, 'fmt_by_attr', 'job_state'))
    fl.append(gen_field('sessid', 'SessID', rj, 'fmt_by_attr', 'session_id'))
    fl.append(gen_field('seqno', 'SeqNo', None, 'fmt_seqno', None))
    fl.append(gen_field('ss', 'Ss', None, 'fmt_jobstate', 'job_state Hold_Types'))
    fl.append(gen_field('stime', 'Stime', None, 'fmt_date', 'stime'))
    fl.append(gen_field('tsk', 'TSK', rj, 'fmt_from_rsrc', 'Resource_List', 'ncpus'))
    fl.append(gen_field('user', 'User', None, 'fmt_by_attr', 'euser'))
    fl.append(gen_field('vmem', 'Vmem', hlrj, 'fmt_from_rsrc_sz', 'resources_used', 'vmem'))
    return fl

def gen_field_list_B():
    fl = []
    dr = {'dj': 'r'}
    de = {'df': '='}
    dre = {'dj': 'r', 'df': '='}
    fl.append(gen_field('server_name', ['Server','name'], de, 'fmt_id', None))
    fl.append(gen_field('jm', 'jm', dre, 'fmt_by_attr', 'max_running'))
    fl.append(gen_field('state_count', ['State count', ''], de, 'fmt_state_count', 'state_count'))
    fl.append(gen_field('default_queue', ['Default','queue'], de, 'fmt_by_attr', 'default_queue'))
    fl.append(gen_field('info', 'Info', de, 'fmt_server_info', 'server_state comment scheduling'))
    return fl

def gen_field_list_Q():
    fl = []
    rr = {'rj': 'r'}
    de = {'df': '='}
    dre = {'rj': 'r', 'df': '='}
    dle = {'rj': 'l', 'df': '='}
    dfltf = {'hj':'r', 'hs':'/', 'df':'='}
    fl.append(gen_field('q_name', ['Queue','name'], de, 'fmt_id', None))
    fl.append(gen_field('q_ncpus', ['Ncpus','max'], dfltf, 'fmt_from_rsrc',
        'resources_max', 'ncpus'))
    fl.append(gen_field('q_ncpus_def', 'def', dle, 'fmt_from_rsrc',
        'resources_default', 'ncpus'))
    fl.append(gen_field('q_time', ['Time','max'], dfltf, 'fmt_from_rsrc_tm',
        'resources_max', 'walltime'))
    fl.append(gen_field('q_time_def', 'def', dle, 'fmt_from_rsrc_tm',
        'resources_default', 'walltime'))
    fl.append(gen_field('q_jm', 'jm', dre, 'fmt_by_attr', 'max_running'))
    fl.append(gen_field('state_count', ['State count', ''], de, 'fmt_state_count', 'state_count'))
    fl.append(gen_field('q_pr', 'pr', dre, 'fmt_by_attr', 'Priority'))
    fl.append(gen_field('q_info', 'Info', de, 'fmt_queue_info', 'enabled started'))
    return fl

def add_server_conn(smap, svr, conn):
    '''Add mappings from server to PBS connection

    Given a server name, look up its fqdn, IP addresses, aliase and
    add them to a mapping from server to connection.

    Args:
        smap = Dictionary mapping names to connections to be updated.
        svr = Server to add
        conn = Connection to associate with server
    Returns:
        None if name lookup failed, else True
    Exit:
        smap updated
    '''
    if svr in smap:
        # Don't replace existing entries with None
        if conn == None:
            return True
    try:
        (hname, aliases, ipaddrs) = socket.gethostbyname_ex(svr)
    except:
        if svr not in smap:
            smap[svr] = None
        return None
    smap[svr] = conn
    smap[hname] = conn
    for x in aliases:
        smap[x] = conn
    for x in ipaddrs:
        smap[x] = conn
    return True

def check_W_bool(name, default=False):
    '''Get boolean value from opts_W

    Args:
        name = nmae of option
        default = value if option not present
    Returns:
        True if option present in opts_W and not set false
        default otherwise
    '''
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        # Option by itself is True
        if wopt == name:
            return True
        # Examine name=value
        if not wopt.startswith(namee):
            continue
        val = wopt[len(namee):].lower()
        if val == 't' or val == 'true' or val == '1':
            return True
        if val == 'f' or val == 'false' or val == '0':
            return False
    return default

def check_W_int(name, default=0):
    '''Get integer value from opts_W

    Args:
        name = name of option
        default = value if option not present
    Returns:
        Integer value of found option
    '''
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        if not wopt.startswith(namee):
            continue
        # Examine name=value
        val = wopt[len(namee):].lower()
        try:
            return int(val)
        except:
            if val == '': return default
            if val == 't': return 1
            if val == 'f': return 0
    return default

def check_W_str(name, default=''):
    global opts_W
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(opts_W)-1, -1, -1):
        wopt = opts_W[idx]
        # Option by itself is default
        if wopt == name:
            return default
        # Examine name=value
        if not wopt.startswith(namee):
            continue
        val = wopt[len(namee):]
        return val
    return default

def format_resvs(all_resvs, host, resv_list):
    '''Get reservations affecting a host

    From the list of all reservations and those that apply to a host,
    create a string with interesting info about the reservations.
    '''
    global gNow
    def safeint(x):
        try:
            t = int(x)
        except:
            t = 0
        return t
    end_of_interest = gNow + 9 * 24 * 3600
    earliest = -1
    missing = 0
    rlist = []
    for r in resv_list:
        for resv_info in all_resvs:
            if resv_info['id'] != r:
                continue
            start = safeint(resv_info['reserve_start'])
            end = safeint(resv_info['reserve_end'])
            if start < end_of_interest and end >= gNow:
                resv_info['rstart'] = start
                resv_info['rend'] = end
                rlist.append(resv_info)
            if earliest < 0 or start < earliest:
                earliest = start
            break
        else:
            missing += 1
    if len(rlist) == 0:
        if missing == 0:
            return ''
        elif missing == 1:
            return 'reservation'
        else:
            return 'reservations'
    # Decide what to do based on earliest matching reservation
    one_day_out = gNow + 24 * 3600
    six_days_out = gNow + 6 * 24 * 3600
    the_time = earliest
    if earliest > one_day_out:
        two_weeks_out = gNow + 14 * 24 * 3600
        if earliest > two_weeks_out:
            fmt = r'Resv on %b %d'
        elif earliest > six_days_out:
            fmt = r'Resv next %a'
        else:
            fmt = r'Resv on %a'
        return time.strftime(fmt, time.localtime(earliest))
    if earliest > gNow:
        if earliest > gNow + 12 * 3600:
            fmt = r'Resv %a %H:%M'
        else:
            fmt = r'Resv at %H:%M'
    else:
        # Active reservation. Find when reservations will end
        start = gNow
        end = gNow
        found = True
        while found:
            found = False
            fstart = start - 30 * 60
            fend = end + 30 * 60
            for ri in rlist:
                rstart = ri['rstart']
                rend = ri['rend']
                if rstart > fend or rend < fstart:
                    continue
                if rstart < start:
                    start = rstart
                    found = True
                if rend > end:
                    end = rend
                    found = True
        if end > one_day_out:
            if end > six_days_out:
                fmt = r'Resv until %b %e'
            else:
                fmt = r'Resv until %a %H:%M'
        else:
            fmt = r'Resv until %H:%M'
        the_time = end
    return time.strftime(fmt, time.localtime(the_time))

def pretty_state_counts(ilist):
    '''Convert state info into "pretty" output

    Args:
        ilist = List of dicts with 'state_count' attributes to be beautified
    Returns:
        A list of strings suitable for printing. The first element is a header
        and the remaining are state counts, one for each element in ilist.
    '''
    sclist = []
    maxsn = []
    for info in ilist:
        state_count = info.get('state_count', '')
        state_names = []
        state_cnts = []
        for one_count in state_count.split():
            mo = re.match(r'([A-Z])\w+:(\d+)', one_count)
            if mo:
                state_names.append(mo.group(1))
                state_cnts.append(mo.group(2))
        if len(state_names) > len(maxsn):
            maxsn = state_names
        sclist.append(state_cnts)
    # Deal with no data
    if len(maxsn) < 1:
        return ['--'] * (len(ilist) + 1)
    # Now, use layout to make into uniform size for all elements of ilist
    cfg = layout.Config()
    idx = 0
    for sn in maxsn:
        idx += 1
        s = '/' if idx < len(maxsn) else ''
        cfg.add_field(sn, hf='_', hj='r', hs=s, df='')
    scrows = layout.layout(cfg, sclist)
    return scrows

def summarize(nlist):
    '''Produce one line summary of multiple nodes

    Args:
        nlist = list of node entries, where each entry is a list with
            the following attributes
            0 node name
            1 CPUs allocated
            2 CPUs free
            3 memory allocated
            4 memory free
            5 task count
            6 job count
            7 interesting info
    Returns:
        List with same elements, summed
    '''
    from nas_field_format import unsuffix, ensuffix
    def safeint(x):
        try:
            t = int(x)
        except:
            t = 0
        return t
    def safememadd(total, addend):
        if total < 0:
            return total
        t = unsuffix(addend)
        return total + t if isinstance(t, int) else -1
    mom_count = len(nlist)
    cpus_alloc = 0
    cpus_free = 0
    mem_alloc = 0
    mem_free = 0
    task_cnt = 0
    job_cnt = 0
    info = nlist[0][-1] if mom_count > 0 else ''
    for mom_info in nlist:
        cpus_alloc += safeint(mom_info[1])
        cpus_free += safeint(mom_info[2])
        mem_alloc = safememadd(mem_alloc, mom_info[3])
        mem_free = safememadd(mem_free, mom_info[4])
        task_cnt += safeint(mom_info[5])
        job_cnt += safeint(mom_info[6])
    # Create result list
    t = 's' if mom_count != 1 else ''
    entry = [ " %d host%1s" % (mom_count, t),
        str(cpus_alloc),
        str(cpus_free),
        ensuffix(mem_alloc) if mem_alloc >= 0 else '--',
        ensuffix(mem_free) if mem_free >= 0 else '--',
        str(task_cnt),
        # Due to multi-node jobs, you cannot just sum job counts.
        # The only accurate job_counts are 0 and 1.
        str(job_cnt) if job_cnt <= 1 else '--',
        info]
    return entry

if __name__ == '__main__':
    sys.exit(main())

# vi:ts=4:sw=4:expandtab
