#!/usr/bin/python3 -I

'''Display information about Altair fairshares

This command displays information about PBS fairshares. It is similar
to pbsfs, but accepts field selections similarly to nas_qstat.
Unlike pbsfs, it is display only. Use pbsfs to alter fairshare entries.
'''

import sys
import os
import argparse
import copy
import re
import signal
import stat
import struct
import time
from sys import stdin, stdout, stderr


long_desc = __doc__
gdebug = ''
version = "0.1"
share_name_map = dict()
share_id_map = dict()

unknown_alloc = 10  # XXX should load from sched_conf
# Constants
FAIRSHARE_ROOT_NAME = 'TREEROOT'
UNKNOWN_GROUP_NAME = 'unknown'
UNSPECIFIED = None
MAGIC_NAME = 'PBS_MAG!'


class Share:
    def __init__(self, name, par_id, grp_id):
        self.name = name
        self.par_id = par_id        # resgroup
        self.grp_id = grp_id        # cresgroup
        self.alloc = UNSPECIFIED    # shares
        self.tree_pct = 0.0         # tree_percentage
        self.grp_pct = 0.0          # shares/group_shares
        self.usage = 0.0            # usage in fairshare_rec units
        self.usage_factor = 0.0     # actual usage vs allocation (range 0 - 1)
        #                             also called fairshare_tree_usage
        self.grp_path = list()      # path from root to node
        self.parent = None          # link up the tree
        self.sibling = None         # chain of nodes with same parent as us
        self.child = None           # link to head of our sibling chain
        self.fs_factor = 0.0
        self.depth = 0              # indent to print in tree form


def main():
    global args, version, gdebug, shost, hostname, pbs_exec, pbs_home
    global sched_priv, groups_file, usage_file
    # Don't catch any signals (so no ugly tracebacks on Ctrl-C).
    for i in range(1, signal.NSIG):
        try:
            signal.signal(i, signal.SIG_DFL)
        except OSError:
            pass
    prog = sys.argv[0].split('/')[-1]
    parser = argparse.ArgumentParser(
        description=long_desc, prog=prog,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('--debug', default=[], action='append',
                        help='Debugging arguments (for developers)')
    parser.add_argument('-f', default=False, action='store_true',
                        help='output one line per attribute')
    parser.add_argument('-t', default=False, action='store_true',
                        help='display as tree')
    parser.add_argument('-c', '--convert', default=False, action='store_true',
                        help='scan job_file to collect usage info')
    parser.add_argument('--job_file', action='store',
                        help='output from qstat -f for usage info')
    parser.add_argument('--new_usage', action='store',
                        help='where to write usage info')
    parser.add_argument('--verbose', '-v', default=0, action='count',
                        help='increase debugging verbosity')
    parser.add_argument('--version', action='version',
                        version='%(prog)s ' + version)
    parser.add_argument('-W', action='append', metavar='display_option',
                        help='options affecting field selection and display.'
                        ' See nas_qstat.1')
    parser.add_argument('shares', nargs=argparse.REMAINDER,
                        help='shares to list')

    args = conf.args = parser.parse_args()
    conf.verbose = verbose = args.verbose
    conf.gdebug = gdebug = ' '.join(args.debug)

    if (ifl.pbs_loadconf(0) == 0):
        print("Cannot get PBS configuration information", file=sys.stderr)
        return 1
    conf.pbs_conf = pbs_conf = ifl.cvar.pbs_conf
    set_paths(pbs_conf)

    default_fields = ['name', 'par_id', 'grp_id', 'alloc', 'pct',
                      'usage', 'ftu', 'fsfact']
    conf.verbose = args.verbose
    levels = 0
    if (levels > 1):
        print("Use only one of TODO B, F, S, f", file=sys.stderr)
        return 1
    # Build list of known fields
    opts_W = args.W
    if opts_W is None:
        opts_W = list()
    conf.opts_W = opts_W
    # Load possible user or system overrides
    more_code = load_userexits('pbsfs')
    if more_code:
        prog = compile(more_code, 'userexit code', 'exec')
        exec(prog, globals(), locals())
    default_W = []
    userexit_post_opts(globals(), locals())
    opts_W[0:0] = default_W
    known_fields = gen_field_list()
    # Scan opts_W for on-the-fly field defs
    define_on_the_fly(known_fields, opts_W)
    fmtr = NAS_field_format(default_fields)
    fmtr.known_fields = known_fields
    userexit_add_fields(globals(), locals())
    # Handle -W options
    (field_list, attr_list, errs) = fmtr.collect_fields()
    if (errs):
        # Check if should just print list of fields
        if field_list is None:
            print('\n'.join(errs))
            return 0
        print(errs, file=sys.stderr)
    rc = fmtr.adjust_formats(field_list)
    if rc is not True:
        print(rc, file=sys.stderr)
        return 1
    fmtr.field_list = field_list
    nas_field_format.set_field_vars(opts_W)
    # Build resource_group tree
    result = load_fs_info(groups_file)
    if isinstance(result, str):
        print(result, file=stderr)
        sys.exit(1)
    (root, patts, weights) = result
    if root is None:
        sys.exit(1)
    # Insert usage info
    if args.convert:
        result = load_usage_from_jobs(args.job_file, root, patts, weights)
    else:
        load_usage(root)
    reconcile_usage(root)
    if args.convert:
        result = write_new_usage(args.new_usage, root)
    if args.f:
        display_f(args, root, "Group Name", "Group")
    # Display it
    display_standard(root, fmtr)
    return 0


def display_f(args, root, item_tag, json_tag):
    return 0


def display_standard(root, fmtr):
    '''Output info in standard format
    TODO
    Args:
        root = tree of info for share groups
        fmtr = field formatter object
    '''
    global args
    c = layout.Config()
    for fld in fmtr.field_list:
        title = fld['title']
        if not title:
            title = fld['name']
        c.add_field(title, ident=fld['name'], **fld['format'])
    rows = list()
    for share in depth_first(root, 0) if args.t else share_id_map.values():
        row = list()
        for f in fmtr.field_list:
            func = globals().get(f['func'], None)
            if not func:
                print(f"Missing defn for function {f['func']}")
                continue
            row.append(func(f, share))
        rows.append(row)
    if rows:
        show_hdr = '-h' not in conf.opts_W
        res = layout.layout(c, rows, show_hdr=show_hdr)
        print('\n'.join([x.rstrip() for x in res]))


def gen_field_list():
    '''Generate list of known fields

    Returns: list of field_info dicts for known fields
    The dict have these key/value pairs
        name: the name of the field
        format: dict suitable for passing to layout.add_field()
        func: name of function to calculate display value
        sources: reservation attributes whose values are needed by func
    '''
    fl = []
    hjr = {'hj': 'r'}
    fl.append(gen_field('name', 'Name', None, 'fmt_fs_name', 'name'))
    fl.append(gen_field('par_id', 'Parent', hjr, 'fmt_fs_int', 'par_id'))
    fl.append(gen_field('grp_id', 'Grp_id', hjr, 'fmt_fs_int', 'grp_id'))
    fl.append(gen_field('alloc', 'Shares', hjr, 'fmt_fs_int', 'alloc'))
    fl.append(gen_field('usage', 'Usage', hjr, 'fmt_fs_usage', 'usage'))
    fl.append(gen_field('pct', 'Share%', hjr, 'fmt_fs_pct', 'tree_pct'))
    fl.append(gen_field('ftu', 'FTU', hjr, 'fmt_fs_factor', 'usage_factor'))
    fl.append(gen_field('fsfact', 'Factor', hjr, 'fmt_fs_factor', 'fs_factor'))
    return fl


def check_W_str(name, default=''):
    namee = name + '='
    # Last match decides, so search backward
    for idx in range(len(conf.opts_W) - 1, -1, -1):
        wopt = conf.opts_W[idx]
        # Option by itself is default
        if wopt == name:
            return default
        # Examine name=value
        if not wopt.startswith(namee):
            continue
        val = wopt[len(namee):]
        return val
    return default


def do_debugging():
    '''Help debugging the program

    Examine an environment variable for overrides to selected paths.
    '''
    global gdebug, mom_priv, pbs_exec, pbs_home
    debugstr = os.getenv('NAS_PBSFS_DEBUG')
    if not debugstr:
        debugstr = ''
    debugstr = gdebug + ' ' + debugstr
    mo = re.search(r'\bdebug\b', debugstr)
    gdebug = True if mo else False
    # Path overrides:
    for s in re.split(r'[\s,]+', debugstr):
        mo = re.match(r'(\w+)=(.+)', s)
        if not mo:
            continue
        (name, path) = mo.group(1, 2)
        if '/' not in path:
            continue
        globals()[name] = path
    return


def calc_fs_factor(tree):
    '''Calculate fairshare_factor

    This is the number to use to learn which entities should be favored
    most when scheduling. Lower is better.

    Args:
        tree = root of fs tree
    '''
    for share in share_id_map.values():
        if share.tree_pct == 0.0:
            share.fs_factor = 0.0
        else:
            share.fs_factor = pow(2, -(share.usage_factor / share.tree_pct))


def calc_fs_tree_usage(tree):
    '''Calculate usage factor for tree

    Each node's usage_factor is calculated. Called fairshare_tree_usage
    in Admin Guide.  The factor takes each node's usage and part of its
    parent's usage into account

    Args:
        tree = base of tree to work on
    '''
    if not tree:
        return
    share = tree.child
    while share:
        share.usage_factor = share.usage / tree.usage
        calc_fs_tree_usage_helper(tree, share.child)
        share = share.sibling


def calc_fs_tree_usage_helper(root, child):
    '''Helper routine to recurse through tree at root

    Args:
        root = base of tree to work on
        child = a node in the tree to start with
    '''
    if not root or not child:
        return
    parent = child.parent
    if not parent:
        return
    portion = child.usage / root.usage
    child.usage_factor = portion + \
        (parent.usage_factor - portion) * child.grp_pct
    calc_fs_tree_usage_helper(root, child.sibling)
    calc_fs_tree_usage_helper(root, child.child)


def calc_fs_percent(root, alloc):
    '''Calc group share percent of total

    Args:
        root = base of subtree
        alloc = allocation for the group
            UNSPECIFIED implies calculate it
    '''

    if not root or not root.parent:
        return
    cur_alloc = alloc if alloc != UNSPECIFIED else count_alloc(root)
    parent = root.parent
    # Detect no alloc
    if cur_alloc * parent.tree_pct == 0:
        root.grp_pct = 0.0
        root.tree_pct = 0.0
    else:
        root.grp_pct = float(root.alloc) / cur_alloc
        root.tree_pct = root.grp_pct * parent.tree_pct
    calc_fs_percent(root.sibling, cur_alloc)
    calc_fs_percent(root.child, UNSPECIFIED)


def count_alloc(share):
    '''Count allocations in a group

    The group includes the share and all of its sibs

    Args:
        share = the start of a sib list
    Returns:
        sum of the allocations for the sib list
    '''
    tot_alloc = 0
    while share:
        if share.alloc:
            tot_alloc += share.alloc
        share = share.sibling
    return tot_alloc


def depth_first(tree, depth):
    '''Visit tree in depth first order

    Args:
        tree to visit
            nodes will have their depth value updated
    Returns
        Tree nodes in depth_first order.
    '''
    if not tree:
        return []
    tree.depth = depth
    clist = depth_first(tree.child, depth+1)
    slist = depth_first(tree.sibling, depth)
    t = [tree]
    t += clist
    t += slist
    return t


def fmt_fs_factor(fi, info):
    '''Format a factor betwen 0 and 1, given by sources'''
    t = fi['sources'][0]
    val = getattr(info, t)
    return "%0.3g" % val


def fmt_fs_int(fi, info):
    '''Format an integer given by sources'''
    t = fi['sources'][0]
    val = getattr(info, t)
    return str(val)


def fmt_fs_name(fi, info):
    '''Format share name'''
    global args
    val = info.name
    if args.t:
        val = ' ' * info.depth + val
    return val


def fmt_fs_pct(fi, info):
    '''Format a percentage given by sources'''
    t = fi['sources'][0]
    val = getattr(info, t) * 100.0
    return "%3.2f%%" % val


def fmt_fs_usage(fi, info):
    '''Format a share usage'''
    usage = info.usage
    return "%.3f" % usage


def insert_child(parent, child):
    '''Add a child to a share's child chain

    In alphabetical order

    Args:
        parent = share to add child to
        child = child to add
    '''
    name = child.name
    cur_child = parent.child
    # Deal with first child
    if not cur_child:
        child.sibling = None
        parent.child = child
        return
    # If new child fits in at beginning
    if name < cur_child.name:
        child.sibling = cur_child
        parent.child = child
        return
    # Scan sib chain to find where to insert
    while cur_child:
        if name > cur_child.name:
            prev = cur_child
            cur_child = cur_child.sibling
            continue
        break
    child.sibling = cur_child
    prev.sibling = child
    return


def load_usage(root):
    '''Read group use data from file

    Args:
        root = root of shares tree
    '''
    with open(usage_file, 'rb') as fd:
        buf = fd.read()
    hdr_fmt = '9sdl'
    sz = struct.calcsize(hdr_fmt)
    header = struct.unpack(hdr_fmt, buf[0:sz])
    # The stuff with partition is because the string fields are zero filled
    # and we need to truncate at the first zero.
    magic = str(header[0].partition(b'\0')[0], encoding='utf-8')
    if magic != MAGIC_NAME or header[1] != 2.0:
        print(f"Bad usage file header: {usage_file}", file=stderr)
        sys.exit(1)
    use_fmt = '50sd'
    for entry in struct.iter_unpack(use_fmt, buf[sz:]):
        name = str(entry[0].partition(b'\0')[0], encoding='utf-8')
        if name not in share_name_map:
            print(f'Usage for unknown share ignored: {name}', file=stderr)
            continue
        share_name_map[name].usage = entry[1]
    return


def load_usage_from_jobs(fname, tree, patts, weights):
    if fname == '-':
        fs = stdin
    else:
        fs = open(fname)
    lines = fd.read()
    if fname != '-':
        fs.close()
    interesting = ['egroup', 'euser', 'resources_used', 'schedselect',
                   'Account_Name']
    jobs = lines_to_stat(lines, None)
    del lines
    for job in jobs:
        entity = set_account_name(job)
        if entity not in share_name_map:
            continue
        sbu_rate = set_sbu_rate(job)
        if sbu_rate is None:
            continue
        effective_wt = calc_aged_walltime(job)
        eff_sbus = sbu_rate * effective_wt
        share = share_name_map[entity]
        share.usage += eff_sbus
    return True


def set_account_name(job):
    entity = job.get('Account_Name')
    if entity:
        return entity:
    egroup = job['egroup']
    euser = job['euser']
    share = get_share(egroup, euser)
    entity = share.name
    job['Account_Name'] = entity
    return entity


def new_group(name, par_id, grp_id):
    '''Create a new share object

    Initialized to default values

    Args:
        name = name of the share
        par_id = resource group this child belongs to
        grp_id = resource group of any children

    Returns:
        Partially filled-out share object
        Object added to share_maps
    '''
    share = Share(name, par_id, grp_id)
    share_name_map[name] = share
    share_id_map[grp_id] = share
    return share


def reconcile_tree(root):
    '''Fill in a bare share tree

    Args:
        root = root of the tree
    Returns:
        True if no problems found
        False if errors reported.
    '''
    # First, build parent, child, and sibling links
    for (name, share) in share_name_map.items():
        par_id = share.par_id
        if par_id < 0:
            continue
        parent = share_id_map[par_id]
        share.parent = parent
        share.par_id = parent.grp_id
        insert_child(parent, share)
    # Now, build the paths from the share to the root
    for share in share_id_map.values():
        share.grp_path = create_group_path(share)
    # Fill in special shares: root and unknown
    root = share_name_map[FAIRSHARE_ROOT_NAME]
    root.tree_pct = 1.0
    root.alloc = 0
    tot_alloc = sum([share.alloc for share in share_id_map.values()])
    root.alloc = tot_alloc
    unk = share_name_map[UNKNOWN_GROUP_NAME]
    unk.alloc = unknown_alloc
    calc_fs_percent(root.child, UNSPECIFIED)
    return True


def reconcile_usage(root):
    # Add current use values for leaf nodes into their ancesters
    for share in share_id_map.values():
        if share.child:
            continue    # Not leaf
        usage = share.usage
        for name in share.grp_path:
            node = share_name_map[name]
            if node is not share:
                node.usage += usage
    calc_fs_tree_usage(root)
    calc_fs_factor(root)
    return True


def set_paths(pbs_conf):
    global pbs_home, pbs_exec, hostname, shost, sched_priv
    global groups_file, usage_file
    pbs_home = pbs_conf.pbs_home_path
    pbs_exec = pbs_conf.pbs_exec_path
    hostname = pbs_conf.pbs_server_name
    shost = hostname.split('.')[0]
    sched_priv = os.path.join(pbs_home, 'sched_priv')
    groups_file = os.path.join(sched_priv, 'resource_group')
    usage_file = os.path.join(sched_priv, 'usage')
    do_debugging()


def create_group_path(share):
    path = list()
    while share:
        path.insert(0, share.name)
        share = share.parent
    return path


def load_fs_info(fname):
    '''Read and parse fairshare info file

    Args:
        fname = path to file to load from
    Returns:
        Tuple (tree, pattern, weights) where
            tree is tree of entity Shares
            patterns is list of tuples (pattern, share) where:
                pattern is a compiled pattern
                share is the Share for the matching entity
            weights is dict with key model_name value (cpus, sbus)
        err string on error
    '''
    try:
        with open(fname) as fs:
            buf = fs.read()
    except OSError:
        return f'Cannot read {fname}'
    (nlines, plines, wlines) = split_share_info(fname, buf)
    # We need the share tree to validate the patterns, so process it first
    tree = build_tree(fname, nlines)
    if isinstance(tree, str):
        return tree
    patt_list = build_patterns(fname, plines, share_name_map)
    if isinstance(patt_list, str):
        return patt_list
    weight_dict = build_weights(fname, wlines)
    if isinstance(weight_dict, str):
        return weight_dict
    return (tree, patt_list, weight_dict)


def build_tree(fname, lines):
    '''Build tree(fname, lines)

    Build tree of Shares from lines
    Lines have the form
        (entity_name grp_id parent_name allocation)
    '''
    root = new_group(FAIRSHARE_ROOT_NAME, -1, 0)
    share_name_map['root'] = root
    for (lineno, flds) in lines:
        loc = f'at {fname}:{lineno}'
        if len(flds) != 4:
            return f'Wrong format {loc}'
        (name, grp_id, parent, alloc) = flds
        if not name.isidentifier():
            return f'Bad group name {name} {loc}'
        try:
            grp_id = int(grp_id)
        except Exception:
            return f'Non_integer grp_id {grp_id} {loc}'
        if not parent.isidentifier():
            return f'Bad parent name {parent} {loc}'
        try:
            alloc = int(alloc)
        except Exception:
            return f'Non-integer allocation {alloc} {loc}'
        # Semantic checks
        if name in share_name_map:
            return f'Duplicate share name {name} {loc}'
        if grp_id in share_id_map:
            return f'Group id already in use: {grp_id} {loc}'
        if parent not in share_name_map:
            return f'Unknown parent share {parent} {loc}'
        par_id = share_name_map[parent].grp_id
        share = new_group(name, par_id, grp_id)
        share.alloc = alloc
    # Add the unknown group at end
    unknown = new_group(UNKNOWN_GROUP_NAME, 0, 1)
    unknown.alloc = unknown_alloc
    result = reconcile_tree(root)
    return root


def build_patterns(fname, plines, entities):
    '''Create list of entity patterns

    Args:
        fname = name of file the patterns came from
        plines = split-out pattern lines
        entities = dict with known entities as keys
    Returns:
        list of (compiled pattern, entity name) tuples in same order
        as in the file.
        returns string message on error
    '''
    plist = list()
    for (lineno, flds) in plines:
        loc = f'at {fname}:{lineno}'
        if len(flds) != 2:
            return f'Invalid pattern line {loc}'
        (patt, entity) = flds
        if entity not in entities:
            return 'Unknown entity name {entity} {loc}'
        try:
            t = re.compile(patt + '$')
        except Exception:
            return f'Invalid pattern {patt} {loc}'
        plist.append((t, entity))
    return plist


def build_weights(fname, wlines):
    '''Create dict of model types and weights

    Args:
        fname = name of file the weights came from
        wlines = split-out model weight lines
    Returns:
        dict with model name as key and (CPUs, SBUs) tuple as value
        returns string message on error
    '''
    weights = dict()
    for (lineno, flds) in wlines:
        loc = f'at {fname}:{lineno}'
        if len(flds) != 3:
            return f'Invalid model line {loc}'
        (name, cpus, sbus) = flds
        if name in weights:
            return f'Duplicate model {name} {loc}'
        try:
            cpus = int(cpus)
        except Exception:
            return f'Invalid #CPUs {cpus} {loc}'
        try:
            sbus = float(sbus)
        except Exception:
            return f'Invalid SBU rating {sbus} {loc}'
        weights[name] = (cpus, sbus)
    return weights


def split_share_info(fname, buf):
    '''Split the text of a shares file into its pieces.

    Examine each line to decide which type it is.
    Remove comments.

    Args:
        fname = name of source file (for error messages)
        buf = contents of file
    Returns:
        tuple of lists (nodes, patterns, weights)
            where each is a list of tuples (lineno, line)
    '''
    nodes = list()
    patterns = list()
    weights = list()
    lineno = 0
    for line in buf.splitlines():
        lineno += 1
        # Truncate line at comments
        if line.startswith('#map') or line.startswith('#model'):
            line = '#' + line[1:].partition('#')[0]
        else:
            line = line.partition('#')[0]
        line = line.strip()
        flds = line.split()
        # skip empty or comment lines
        if line == '':
            continue
        if flds[0] == '#map':
            patterns.append((lineno, flds[1:]))
            continue
        if flds[0] == '#model':
            weights.append((lineno, flds[1:]))
            continue
        nodes.append((lineno, flds))
    return (nodes, patterns, weights)


if __name__ == '__main__':
    for name, val in sys.modules.items():
        src = str(val)
        pcs = src.split()
        pathpart = pcs[-1]
        path = pathpart[1:-2]
        if path in ['built-in', 'frozen']:
            continue
        if name == '__main__':
            # For debugging, we might need to
            # add the directory where the script
            # resides back to sys.path, if
            # the -I flag removed it.
            # First, though, deal with invoked through symlink.
            t = os.path.dirname(path)
            sb = os.lstat(path)
            if stat.S_ISLNK(sb.st_mode):
                r = os.readlink(path)
                t = os.path.join(t, r)
                t = os.path.dirname(t)
            t = os.path.abspath(t)
            if t not in sys.path:
                sys.path.insert(0, t)
            # If path ends in bin, try to add equivalent lib directory
            (head, tail) = os.path.split(t)
            if tail != 'bin':
                continue
            t = os.path.join(head, 'lib')
            if t in sys.path:
                # Already there
                continue
            if not os.path.exists(t):
                continue
    import nas_xstat_config as conf
    import pbs_ifl as ifl
    from nas_pbsutil import *
    import nas_layout as layout
    import nas_field_format
    from nas_field_format import NAS_field_format, gen_field, define_on_the_fly

    sys.exit(main())
# vi:ts=4:sw=4:expandtab
